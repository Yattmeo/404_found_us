{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21fd2253",
   "metadata": {},
   "source": [
    "# Clustering Analysis on Merchant Cost Patterns\n",
    "\n",
    "## Notebook Overview\n",
    "\n",
    "This notebook performs multiple clustering methodologies on merchant-level features derived from transaction cost data for MCC 5411 (Grocery Stores).\n",
    "\n",
    "### Features Used\n",
    "- `cost_percent`: Mean processing cost as percentage of transaction amount per merchant\n",
    "- `cost_percent_stdev`: Standard deviation of cost percentage per merchant\n",
    "\n",
    "### Datasets\n",
    "- **Raw Data**: `df_*_base.csv` - Original values without normalization\n",
    "- **Z-Scored Data**: `df_*_base_zscored.csv` - Pre-normalized values\n",
    "- **Splits**: Train (2017), Validate (2018), Test (2019)\n",
    "\n",
    "### Clustering Methods\n",
    "1. **K-Means** - Partition-based clustering with k=2-15 testing\n",
    "2. **Hierarchical Clustering** - Agglomerative clustering with dendrogram visualization\n",
    "3. **DBSCAN** - Density-based clustering with noise detection\n",
    "\n",
    "### Analysis Steps\n",
    "1. **Data Loading & Quality Checks** - Load data, handle NaN/infinity values\n",
    "2. **K-Means Clustering** - Test different k values, compare raw vs z-scored\n",
    "3. **Hierarchical Clustering** - Ward linkage, dendrogram analysis\n",
    "4. **DBSCAN** - Density-based clustering, epsilon tuning\n",
    "5. **Methods Comparison** - Compare all clustering approaches\n",
    "\n",
    "### Evaluation Metrics\n",
    "- **Silhouette Score**: Measures cluster cohesion and separation (higher is better, range [-1, 1])\n",
    "- **Davies-Bouldin Index**: Measures cluster similarity (lower is better, range [0, âˆž))\n",
    "- **Inertia**: Within-cluster sum of squares (elbow method)\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8defc4",
   "metadata": {},
   "source": [
    "## 1. Setup & Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07ecf9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3031113f",
   "metadata": {},
   "source": [
    "## 2. Data Loading & Quality Checks (Raw Data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62aa021e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load datasets\n",
    "\n",
    "df_train = pd.read_csv('base_features/df_train_base.csv')\n",
    "df_validate = pd.read_csv('base_features/df_validate_base.csv')\n",
    "df_test = pd.read_csv('base_features/df_test_base.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d787b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_validate.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8843603b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diagnostic: Check for infinity/NaN in raw loaded data\n",
    "print(\"=== CHECKING RAW DATA FROM CSV ===\\n\")\n",
    "\n",
    "for name, df in [('Train', df_train), ('Validate', df_validate), ('Test', df_test)]:\n",
    "    print(f\"\\n{name} dataset:\")\n",
    "    print(f\"  Shape: {df.shape}\")\n",
    "    print(f\"  NaN count: {df.isna().sum().sum()}\")\n",
    "    print(f\"  Inf count: {np.isinf(df.select_dtypes(include=[np.number])).sum().sum()}\")\n",
    "    \n",
    "    # Check actual min/max values\n",
    "    numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "    for col in numeric_cols:\n",
    "        col_min = df[col].min()\n",
    "        col_max = df[col].max()\n",
    "        if np.isinf(col_min) or np.isinf(col_max) or abs(col_max) > 1e10:\n",
    "            print(f\"  WARNING - {col}: min={col_min}, max={col_max}\")\n",
    "            # Show which merchants have infinity\n",
    "            inf_rows = np.isinf(df[col])\n",
    "            if inf_rows.sum() > 0:\n",
    "                print(f\"    Merchants with infinity in {col}: {df.loc[inf_rows, 'merchant_id'].tolist()[:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e124fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigate merchant 50783 specifically\n",
    "print(\"=== INVESTIGATING MERCHANT 50783 ===\\n\")\n",
    "\n",
    "merchant_id = 50783\n",
    "\n",
    "# Check in each dataset\n",
    "for name, df in [('Train', df_train), ('Validate', df_validate), ('Test', df_test)]:\n",
    "    if merchant_id in df['merchant_id'].values:\n",
    "        print(f\"\\nFound in {name} dataset:\")\n",
    "        merchant_data = df[df['merchant_id'] == merchant_id]\n",
    "        print(merchant_data.T)  # Transpose for easier reading\n",
    "        \n",
    "        # Check for inf/nan\n",
    "        print(f\"\\nHas NaN: {merchant_data.isna().any().any()}\")\n",
    "        print(f\"Has Inf: {np.isinf(merchant_data.select_dtypes(include=[np.number])).any().any()}\")\n",
    "        \n",
    "        # Show inf columns\n",
    "        if np.isinf(merchant_data.select_dtypes(include=[np.number])).any().any():\n",
    "            inf_cols = merchant_data.select_dtypes(include=[np.number]).columns[\n",
    "                np.isinf(merchant_data.select_dtypes(include=[np.number])).any()\n",
    "            ]\n",
    "            print(f\"Columns with Inf: {inf_cols.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19505ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for and handle missing values\n",
    "print(\"=== DATA QUALITY CHECK ===\\n\")\n",
    "\n",
    "for name, df in [('Train', df_train), ('Validate', df_validate), ('Test', df_test)]:\n",
    "    null_counts = df.isnull().sum()\n",
    "    if null_counts.sum() > 0:\n",
    "        print(f\"{name} dataset - Missing values:\")\n",
    "        print(null_counts[null_counts > 0])\n",
    "        print()\n",
    "\n",
    "# Fill NaN values with 0 (for cost_type percentages, NaN means 0% of that type)\n",
    "print(\"Filling NaN values with 0...\")\n",
    "df_train = df_train.fillna(0)\n",
    "df_validate = df_validate.fillna(0)\n",
    "df_test = df_test.fillna(0)\n",
    "\n",
    "# Check for and handle infinite values\n",
    "print(\"\\nChecking for infinite values...\")\n",
    "for name, df in [('Train', df_train), ('Validate', df_validate), ('Test', df_test)]:\n",
    "    inf_mask = np.isinf(df.select_dtypes(include=[np.number])).any(axis=1)\n",
    "    if inf_mask.sum() > 0:\n",
    "        print(f\"{name}: {inf_mask.sum()} rows with infinite values\")\n",
    "\n",
    "# Replace infinite values with 0\n",
    "df_train = df_train.replace([np.inf, -np.inf], 0)\n",
    "df_validate = df_validate.replace([np.inf, -np.inf], 0)\n",
    "df_test = df_test.replace([np.inf, -np.inf], 0)\n",
    "\n",
    "print(\"\\nData cleaned successfully!\")\n",
    "print(f\"Train: {df_train.shape}, Validate: {df_validate.shape}, Test: {df_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df6a9ec",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Advanced K-Means Hyperparameter Tuning\n",
    "\n",
    "Beyond just testing different k values, we can optimize other K-Means hyperparameters:\n",
    "- **init**: Initialization method ('k-means++' is smarter, 'random' is faster)\n",
    "- **n_init**: Number of times algorithm runs with different centroid seeds (more is better but slower)\n",
    "- **max_iter**: Maximum iterations (usually 300 is sufficient)\n",
    "\n",
    "### 3.1 K-Means Hyperparameter Tuning - Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a57639",
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Means Comprehensive Hyperparameter Tuning - Raw Data\n",
    "print(\"=\"*80)\n",
    "print(\"K-MEANS COMPREHENSIVE HYPERPARAMETER TUNING - RAW DATA\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Define parameter grid\n",
    "k_values = list(range(2, 11))  # Test k from 2 to 10\n",
    "init_methods = ['k-means++', 'random']\n",
    "n_init_values = [10, 20, 50]  # Number of random initializations\n",
    "\n",
    "kmeans_tuning_results = []\n",
    "\n",
    "print(\"\\nTesting combinations of k, init method, and n_init...\")\n",
    "print(\"(This may take a moment)\\n\")\n",
    "\n",
    "for k in k_values:\n",
    "    for init_method in init_methods:\n",
    "        for n_init in n_init_values:\n",
    "            # Fit K-Means\n",
    "            kmeans_test = KMeans(n_clusters=k, init=init_method, n_init=n_init, random_state=42, max_iter=300)\n",
    "            train_labels = kmeans_test.fit_predict(X_train_scaled)\n",
    "            \n",
    "            # Predict on validation set\n",
    "            validate_labels = kmeans_test.predict(X_validate_scaled)\n",
    "            \n",
    "            # Calculate metrics\n",
    "            train_sil = silhouette_score(X_train_scaled, train_labels)\n",
    "            train_db = davies_bouldin_score(X_train_scaled, train_labels)\n",
    "            train_inertia = kmeans_test.inertia_\n",
    "            \n",
    "            validate_sil = silhouette_score(X_validate_scaled, validate_labels)\n",
    "            validate_db = davies_bouldin_score(X_validate_scaled, validate_labels)\n",
    "            \n",
    "            kmeans_tuning_results.append({\n",
    "                'k': k,\n",
    "                'init': init_method,\n",
    "                'n_init': n_init,\n",
    "                'train_silhouette': train_sil,\n",
    "                'train_davies_bouldin': train_db,\n",
    "                'train_inertia': train_inertia,\n",
    "                'validate_silhouette': validate_sil,\n",
    "                'validate_davies_bouldin': validate_db\n",
    "            })\n",
    "\n",
    "# Convert to DataFrame\n",
    "kmeans_tuning_df = pd.DataFrame(kmeans_tuning_results)\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"TUNING RESULTS SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Find best parameters based on validation silhouette score\n",
    "best_kmeans = kmeans_tuning_df.loc[kmeans_tuning_df['validate_silhouette'].idxmax()]\n",
    "\n",
    "print(f\"\\nBest Parameters (by Validation Silhouette Score):\")\n",
    "print(f\"  k = {int(best_kmeans['k'])}\")\n",
    "print(f\"  init = '{best_kmeans['init']}'\")\n",
    "print(f\"  n_init = {int(best_kmeans['n_init'])}\")\n",
    "print(f\"\\nExpected Performance:\")\n",
    "print(f\"  Train Silhouette: {best_kmeans['train_silhouette']:.4f}\")\n",
    "print(f\"  Train Davies-Bouldin: {best_kmeans['train_davies_bouldin']:.4f}\")\n",
    "print(f\"  Validate Silhouette: {best_kmeans['validate_silhouette']:.4f}\")\n",
    "print(f\"  Validate Davies-Bouldin: {best_kmeans['validate_davies_bouldin']:.4f}\")\n",
    "\n",
    "# Show top 10 configurations\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"TOP 10 CONFIGURATIONS (by Validation Silhouette Score):\")\n",
    "print(f\"{'='*80}\")\n",
    "top_kmeans = kmeans_tuning_df.nlargest(10, 'validate_silhouette')[['k', 'init', 'n_init', 'train_silhouette', 'validate_silhouette', 'train_davies_bouldin', 'validate_davies_bouldin']]\n",
    "print(top_kmeans.to_string(index=False))\n",
    "\n",
    "# Analysis by init method\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"PERFORMANCE COMPARISON BY INITIALIZATION METHOD:\")\n",
    "print(f\"{'='*80}\\n\")\n",
    "init_comparison = kmeans_tuning_df.groupby('init').agg({\n",
    "    'validate_silhouette': ['mean', 'std', 'max'],\n",
    "    'validate_davies_bouldin': ['mean', 'std', 'min']\n",
    "}).round(4)\n",
    "print(init_comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19d2619",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of K-Means Hyperparameter Tuning - Raw Data\n",
    "fig, axes = plt.subplots(2, 3, figsize=(20, 12))\n",
    "fig.suptitle('K-Means Hyperparameter Tuning Results - Raw Data', fontsize=16, y=0.995)\n",
    "\n",
    "# For each init method, create a heatmap\n",
    "for idx, init_method in enumerate(['k-means++', 'random']):\n",
    "    # Filter data for this init method\n",
    "    data_subset = kmeans_tuning_df[kmeans_tuning_df['init'] == init_method]\n",
    "    \n",
    "    # Create pivot tables\n",
    "    sil_pivot = data_subset.pivot(index='n_init', columns='k', values='validate_silhouette')\n",
    "    db_pivot = data_subset.pivot(index='n_init', columns='k', values='validate_davies_bouldin')\n",
    "    inertia_pivot = data_subset.pivot(index='n_init', columns='k', values='train_inertia')\n",
    "    \n",
    "    # Silhouette Score\n",
    "    sns.heatmap(sil_pivot, annot=True, fmt='.3f', cmap='RdYlGn', ax=axes[idx, 0], \n",
    "                cbar_kws={'label': 'Silhouette Score'}, vmin=0, vmax=0.8)\n",
    "    axes[idx, 0].set_title(f'Validation Silhouette Score\\n(init={init_method})')\n",
    "    axes[idx, 0].set_xlabel('Number of Clusters (k)')\n",
    "    axes[idx, 0].set_ylabel('n_init')\n",
    "    \n",
    "    # Davies-Bouldin Index (lower is better, so reverse colormap)\n",
    "    sns.heatmap(db_pivot, annot=True, fmt='.3f', cmap='RdYlGn_r', ax=axes[idx, 1],\n",
    "                cbar_kws={'label': 'Davies-Bouldin Index'})\n",
    "    axes[idx, 1].set_title(f'Validation Davies-Bouldin Index\\n(init={init_method})')\n",
    "    axes[idx, 1].set_xlabel('Number of Clusters (k)')\n",
    "    axes[idx, 1].set_ylabel('n_init')\n",
    "    \n",
    "    # Inertia\n",
    "    sns.heatmap(inertia_pivot, annot=True, fmt='.0f', cmap='viridis', ax=axes[idx, 2],\n",
    "                cbar_kws={'label': 'Inertia'})\n",
    "    axes[idx, 2].set_title(f'Training Inertia\\n(init={init_method})')\n",
    "    axes[idx, 2].set_xlabel('Number of Clusters (k)')\n",
    "    axes[idx, 2].set_ylabel('n_init')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Comparison plot: Init method effect on performance\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 5))\n",
    "\n",
    "for init_method in ['k-means++', 'random']:\n",
    "    data_subset = kmeans_tuning_df[kmeans_tuning_df['init'] == init_method]\n",
    "    # Average across n_init values for each k\n",
    "    avg_by_k = data_subset.groupby('k').agg({\n",
    "        'validate_silhouette': ['mean', 'std'],\n",
    "        'validate_davies_bouldin': ['mean', 'std']\n",
    "    })\n",
    "    \n",
    "    axes[0].plot(avg_by_k.index, avg_by_k[('validate_silhouette', 'mean')], \n",
    "                marker='o', label=init_method, linewidth=2)\n",
    "    axes[0].fill_between(avg_by_k.index, \n",
    "                         avg_by_k[('validate_silhouette', 'mean')] - avg_by_k[('validate_silhouette', 'std')],\n",
    "                         avg_by_k[('validate_silhouette', 'mean')] + avg_by_k[('validate_silhouette', 'std')],\n",
    "                         alpha=0.2)\n",
    "    \n",
    "    axes[1].plot(avg_by_k.index, avg_by_k[('validate_davies_bouldin', 'mean')], \n",
    "                marker='o', label=init_method, linewidth=2)\n",
    "    axes[1].fill_between(avg_by_k.index, \n",
    "                         avg_by_k[('validate_davies_bouldin', 'mean')] - avg_by_k[('validate_davies_bouldin', 'std')],\n",
    "                         avg_by_k[('validate_davies_bouldin', 'mean')] + avg_by_k[('validate_davies_bouldin', 'std')],\n",
    "                         alpha=0.2)\n",
    "\n",
    "axes[0].set_xlabel('Number of Clusters (k)', fontsize=12)\n",
    "axes[0].set_ylabel('Validation Silhouette Score', fontsize=12)\n",
    "axes[0].set_title('Effect of Init Method on Silhouette Score', fontsize=14)\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1].set_xlabel('Number of Clusters (k)', fontsize=12)\n",
    "axes[1].set_ylabel('Validation Davies-Bouldin Index', fontsize=12)\n",
    "axes[1].set_title('Effect of Init Method on Davies-Bouldin Index', fontsize=14)\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908eb087",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare both results\n",
    "\n",
    "print(\"=== COMPARISON OF CLUSTERING RESULTS ===\\n\")\n",
    "print(f\"Original Data Clustering (k={optimal_k}):\")\n",
    "print(f\"  Train Silhouette Score: {train_silhouette:.4f}\")\n",
    "print(f\"  Train Davies-Bouldin Index: {train_davies_bouldin:.4f}\")\n",
    "print(f\"  Validate Silhouette Score: {validate_silhouette:.4f}\")\n",
    "print(f\"  Validate Davies-Bouldin Index: {validate_davies_bouldin:.4f}\")\n",
    "print(f\"  Test Silhouette Score: {test_silhouette:.4f}\")\n",
    "print(f\"  Test Davies-Bouldin Index: {test_davies_bouldin:.4f}\")\n",
    "\n",
    "print(f\"\\nZ-Scored Data Clustering (k={optimal_k_z}):\")\n",
    "print(f\"  Train Silhouette Score: {train_silhouette_z:.4f}\")\n",
    "print(f\"  Train Davies-Bouldin Index: {train_davies_bouldin_z:.4f}\")\n",
    "print(f\"  Validate Silhouette Score: {validate_silhouette_z:.4f}\")\n",
    "print(f\"  Validate Davies-Bouldin Index: {validate_davies_bouldin_z:.4f}\")\n",
    "print(f\"  Test Silhouette Score: {test_silhouette_z:.4f}\")\n",
    "print(f\"  Test Davies-Bouldin Index: {test_davies_bouldin_z:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a10326",
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Means Comprehensive Hyperparameter Tuning - Z-Scored Data\n",
    "print(\"=\"*80)\n",
    "print(\"K-MEANS COMPREHENSIVE HYPERPARAMETER TUNING - Z-SCORED DATA\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Define parameter grid\n",
    "k_values_z = list(range(2, 11))\n",
    "init_methods_z = ['k-means++', 'random']\n",
    "n_init_values_z = [10, 20, 50]\n",
    "\n",
    "kmeans_tuning_results_z = []\n",
    "\n",
    "print(\"\\nTesting combinations of k, init method, and n_init...\")\n",
    "print(\"(This may take a moment)\\n\")\n",
    "\n",
    "for k in k_values_z:\n",
    "    for init_method in init_methods_z:\n",
    "        for n_init in n_init_values_z:\n",
    "            # Fit K-Means\n",
    "            kmeans_test_z = KMeans(n_clusters=k, init=init_method, n_init=n_init, random_state=42, max_iter=300)\n",
    "            train_labels_z = kmeans_test_z.fit_predict(X_train_z)\n",
    "            \n",
    "            # Predict on validation set\n",
    "            validate_labels_z = kmeans_test_z.predict(X_validate_z)\n",
    "            \n",
    "            # Calculate metrics\n",
    "            train_sil_z = silhouette_score(X_train_z, train_labels_z)\n",
    "            train_db_z = davies_bouldin_score(X_train_z, train_labels_z)\n",
    "            train_inertia_z = kmeans_test_z.inertia_\n",
    "            \n",
    "            validate_sil_z = silhouette_score(X_validate_z, validate_labels_z)\n",
    "            validate_db_z = davies_bouldin_score(X_validate_z, validate_labels_z)\n",
    "            \n",
    "            kmeans_tuning_results_z.append({\n",
    "                'k': k,\n",
    "                'init': init_method,\n",
    "                'n_init': n_init,\n",
    "                'train_silhouette': train_sil_z,\n",
    "                'train_davies_bouldin': train_db_z,\n",
    "                'train_inertia': train_inertia_z,\n",
    "                'validate_silhouette': validate_sil_z,\n",
    "                'validate_davies_bouldin': validate_db_z\n",
    "            })\n",
    "\n",
    "# Convert to DataFrame\n",
    "kmeans_tuning_df_z = pd.DataFrame(kmeans_tuning_results_z)\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"TUNING RESULTS SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Find best parameters\n",
    "best_kmeans_z = kmeans_tuning_df_z.loc[kmeans_tuning_df_z['validate_silhouette'].idxmax()]\n",
    "\n",
    "print(f\"\\nBest Parameters (by Validation Silhouette Score):\")\n",
    "print(f\"  k = {int(best_kmeans_z['k'])}\")\n",
    "print(f\"  init = '{best_kmeans_z['init']}'\")\n",
    "print(f\"  n_init = {int(best_kmeans_z['n_init'])}\")\n",
    "print(f\"\\nExpected Performance:\")\n",
    "print(f\"  Train Silhouette: {best_kmeans_z['train_silhouette']:.4f}\")\n",
    "print(f\"  Train Davies-Bouldin: {best_kmeans_z['train_davies_bouldin']:.4f}\")\n",
    "print(f\"  Validate Silhouette: {best_kmeans_z['validate_silhouette']:.4f}\")\n",
    "print(f\"  Validate Davies-Bouldin: {best_kmeans_z['validate_davies_bouldin']:.4f}\")\n",
    "\n",
    "# Show top 10 configurations\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"TOP 10 CONFIGURATIONS (by Validation Silhouette Score):\")\n",
    "print(f\"{'='*80}\")\n",
    "top_kmeans_z = kmeans_tuning_df_z.nlargest(10, 'validate_silhouette')[['k', 'init', 'n_init', 'train_silhouette', 'validate_silhouette', 'train_davies_bouldin', 'validate_davies_bouldin']]\n",
    "print(top_kmeans_z.to_string(index=False))\n",
    "\n",
    "# Analysis by init method\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"PERFORMANCE COMPARISON BY INITIALIZATION METHOD:\")\n",
    "print(f\"{'='*80}\\n\")\n",
    "init_comparison_z = kmeans_tuning_df_z.groupby('init').agg({\n",
    "    'validate_silhouette': ['mean', 'std', 'max'],\n",
    "    'validate_davies_bouldin': ['mean', 'std', 'min']\n",
    "}).round(4)\n",
    "print(init_comparison_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd6a037",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of K-Means Hyperparameter Tuning - Z-Scored Data\n",
    "fig, axes = plt.subplots(2, 3, figsize=(20, 12))\n",
    "fig.suptitle('K-Means Hyperparameter Tuning Results - Z-Scored Data', fontsize=16, y=0.995)\n",
    "\n",
    "# For each init method, create a heatmap\n",
    "for idx, init_method in enumerate(['k-means++', 'random']):\n",
    "    # Filter data for this init method\n",
    "    data_subset_z = kmeans_tuning_df_z[kmeans_tuning_df_z['init'] == init_method]\n",
    "    \n",
    "    # Create pivot tables\n",
    "    sil_pivot_z = data_subset_z.pivot(index='n_init', columns='k', values='validate_silhouette')\n",
    "    db_pivot_z = data_subset_z.pivot(index='n_init', columns='k', values='validate_davies_bouldin')\n",
    "    inertia_pivot_z = data_subset_z.pivot(index='n_init', columns='k', values='train_inertia')\n",
    "    \n",
    "    # Silhouette Score\n",
    "    sns.heatmap(sil_pivot_z, annot=True, fmt='.3f', cmap='RdYlGn', ax=axes[idx, 0], \n",
    "                cbar_kws={'label': 'Silhouette Score'}, vmin=0, vmax=0.8)\n",
    "    axes[idx, 0].set_title(f'Validation Silhouette Score\\n(init={init_method})')\n",
    "    axes[idx, 0].set_xlabel('Number of Clusters (k)')\n",
    "    axes[idx, 0].set_ylabel('n_init')\n",
    "    \n",
    "    # Davies-Bouldin Index (lower is better, so reverse colormap)\n",
    "    sns.heatmap(db_pivot_z, annot=True, fmt='.3f', cmap='RdYlGn_r', ax=axes[idx, 1],\n",
    "                cbar_kws={'label': 'Davies-Bouldin Index'})\n",
    "    axes[idx, 1].set_title(f'Validation Davies-Bouldin Index\\n(init={init_method})')\n",
    "    axes[idx, 1].set_xlabel('Number of Clusters (k)')\n",
    "    axes[idx, 1].set_ylabel('n_init')\n",
    "    \n",
    "    # Inertia\n",
    "    sns.heatmap(inertia_pivot_z, annot=True, fmt='.0f', cmap='viridis', ax=axes[idx, 2],\n",
    "                cbar_kws={'label': 'Inertia'})\n",
    "    axes[idx, 2].set_title(f'Training Inertia\\n(init={init_method})')\n",
    "    axes[idx, 2].set_xlabel('Number of Clusters (k)')\n",
    "    axes[idx, 2].set_ylabel('n_init')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Comparison plot: Init method effect on performance\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 5))\n",
    "\n",
    "for init_method in ['k-means++', 'random']:\n",
    "    data_subset_z = kmeans_tuning_df_z[kmeans_tuning_df_z['init'] == init_method]\n",
    "    # Average across n_init values for each k\n",
    "    avg_by_k_z = data_subset_z.groupby('k').agg({\n",
    "        'validate_silhouette': ['mean', 'std'],\n",
    "        'validate_davies_bouldin': ['mean', 'std']\n",
    "    })\n",
    "    \n",
    "    axes[0].plot(avg_by_k_z.index, avg_by_k_z[('validate_silhouette', 'mean')], \n",
    "                marker='o', label=init_method, linewidth=2)\n",
    "    axes[0].fill_between(avg_by_k_z.index, \n",
    "                         avg_by_k_z[('validate_silhouette', 'mean')] - avg_by_k_z[('validate_silhouette', 'std')],\n",
    "                         avg_by_k_z[('validate_silhouette', 'mean')] + avg_by_k_z[('validate_silhouette', 'std')],\n",
    "                         alpha=0.2)\n",
    "    \n",
    "    axes[1].plot(avg_by_k_z.index, avg_by_k_z[('validate_davies_bouldin', 'mean')], \n",
    "                marker='o', label=init_method, linewidth=2)\n",
    "    axes[1].fill_between(avg_by_k_z.index, \n",
    "                         avg_by_k_z[('validate_davies_bouldin', 'mean')] - avg_by_k_z[('validate_davies_bouldin', 'std')],\n",
    "                         avg_by_k_z[('validate_davies_bouldin', 'mean')] + avg_by_k_z[('validate_davies_bouldin', 'std')],\n",
    "                         alpha=0.2)\n",
    "\n",
    "axes[0].set_xlabel('Number of Clusters (k)', fontsize=12)\n",
    "axes[0].set_ylabel('Validation Silhouette Score', fontsize=12)\n",
    "axes[0].set_title('Effect of Init Method on Silhouette Score (Z-Scored)', fontsize=14)\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1].set_xlabel('Number of Clusters (k)', fontsize=12)\n",
    "axes[1].set_ylabel('Validation Davies-Bouldin Index', fontsize=12)\n",
    "axes[1].set_title('Effect of Init Method on Davies-Bouldin Index (Z-Scored)', fontsize=14)\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9366bc3",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Advanced Hierarchical Clustering Hyperparameter Tuning\n",
    "\n",
    "Hierarchical clustering has two main hyperparameters:\n",
    "- **Linkage Method**: How to calculate distance between clusters (ward, complete, average, single)\n",
    "- **Number of Clusters (n_clusters)**: Where to cut the dendrogram\n",
    "\n",
    "We'll test all combinations comprehensively for both raw and z-scored data.\n",
    "\n",
    "### 4.1 Hierarchical Hyperparameter Tuning - Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9804371c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hierarchical Clustering Comprehensive Hyperparameter Tuning - Raw Data\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage, fcluster\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"HIERARCHICAL CLUSTERING COMPREHENSIVE HYPERPARAMETER TUNING - RAW DATA\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Define parameter grid\n",
    "linkage_methods = ['ward', 'complete', 'average', 'single']\n",
    "n_clusters_range = list(range(2, 11))\n",
    "\n",
    "hierarchical_tuning_results = []\n",
    "\n",
    "print(\"\\nTesting combinations of linkage methods and n_clusters...\")\n",
    "print(\"(This may take a moment)\\n\")\n",
    "\n",
    "for linkage_method in linkage_methods:\n",
    "    # Compute linkage matrix\n",
    "    print(f\"Computing {linkage_method} linkage...\")\n",
    "    linkage_matrix = linkage(X_train_scaled, method=linkage_method)\n",
    "    \n",
    "    for n_clusters in n_clusters_range:\n",
    "        # Cut dendrogram at specific n_clusters\n",
    "        cluster_labels_train = fcluster(linkage_matrix, n_clusters, criterion='maxclust') - 1\n",
    "        \n",
    "        # Compute cluster centers for prediction\n",
    "        cluster_centers = []\n",
    "        for i in range(n_clusters):\n",
    "            cluster_mask = cluster_labels_train == i\n",
    "            if np.sum(cluster_mask) > 0:  # Check if cluster has points\n",
    "                center = X_train_scaled[cluster_mask].mean(axis=0)\n",
    "                cluster_centers.append(center)\n",
    "        \n",
    "        if len(cluster_centers) < n_clusters:\n",
    "            print(f\"  Warning: {linkage_method} with n_clusters={n_clusters} produced {len(cluster_centers)} clusters\")\n",
    "            continue\n",
    "            \n",
    "        cluster_centers = np.array(cluster_centers)\n",
    "        \n",
    "        # Assign validation points to nearest cluster center\n",
    "        cluster_labels_validate = cdist(X_validate_scaled, cluster_centers).argmin(axis=1)\n",
    "        \n",
    "        # Check if we have at least 2 unique clusters in both train and validate\n",
    "        n_train_clusters = len(np.unique(cluster_labels_train))\n",
    "        n_validate_clusters = len(np.unique(cluster_labels_validate))\n",
    "        \n",
    "        if n_train_clusters < 2 or n_validate_clusters < 2:\n",
    "            print(f\"  Skipping: {linkage_method} with n_clusters={n_clusters} - insufficient clusters (train={n_train_clusters}, val={n_validate_clusters})\")\n",
    "            continue\n",
    "        \n",
    "        # Calculate metrics\n",
    "        train_sil = silhouette_score(X_train_scaled, cluster_labels_train)\n",
    "        train_db = davies_bouldin_score(X_train_scaled, cluster_labels_train)\n",
    "        \n",
    "        validate_sil = silhouette_score(X_validate_scaled, cluster_labels_validate)\n",
    "        validate_db = davies_bouldin_score(X_validate_scaled, cluster_labels_validate)\n",
    "        \n",
    "        hierarchical_tuning_results.append({\n",
    "            'linkage': linkage_method,\n",
    "            'n_clusters': n_clusters,\n",
    "            'train_silhouette': train_sil,\n",
    "            'train_davies_bouldin': train_db,\n",
    "            'validate_silhouette': validate_sil,\n",
    "            'validate_davies_bouldin': validate_db\n",
    "        })\n",
    "\n",
    "# Convert to DataFrame\n",
    "hierarchical_tuning_df = pd.DataFrame(hierarchical_tuning_results)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TUNING RESULTS SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Find best parameters\n",
    "best_hierarchical = hierarchical_tuning_df.loc[hierarchical_tuning_df['validate_silhouette'].idxmax()]\n",
    "\n",
    "print(f\"\\nBest Parameters (by Validation Silhouette Score):\")\n",
    "print(f\"  Linkage Method = '{best_hierarchical['linkage']}'\")\n",
    "print(f\"  n_clusters = {int(best_hierarchical['n_clusters'])}\")\n",
    "print(f\"\\nExpected Performance:\")\n",
    "print(f\"  Train Silhouette: {best_hierarchical['train_silhouette']:.4f}\")\n",
    "print(f\"  Train Davies-Bouldin: {best_hierarchical['train_davies_bouldin']:.4f}\")\n",
    "print(f\"  Validate Silhouette: {best_hierarchical['validate_silhouette']:.4f}\")\n",
    "print(f\"  Validate Davies-Bouldin: {best_hierarchical['validate_davies_bouldin']:.4f}\")\n",
    "\n",
    "# Show top 10 configurations\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"TOP 10 CONFIGURATIONS (by Validation Silhouette Score):\")\n",
    "print(f\"{'='*80}\")\n",
    "top_hierarchical = hierarchical_tuning_df.nlargest(10, 'validate_silhouette')[['linkage', 'n_clusters', 'train_silhouette', 'validate_silhouette', 'train_davies_bouldin', 'validate_davies_bouldin']]\n",
    "print(top_hierarchical.to_string(index=False))\n",
    "\n",
    "# Analysis by linkage method\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"PERFORMANCE COMPARISON BY LINKAGE METHOD:\")\n",
    "print(f\"{'='*80}\\n\")\n",
    "linkage_comparison = hierarchical_tuning_df.groupby('linkage').agg({\n",
    "    'validate_silhouette': ['mean', 'std', 'max'],\n",
    "    'validate_davies_bouldin': ['mean', 'std', 'min']\n",
    "}).round(4)\n",
    "print(linkage_comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3db266f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of Hierarchical Hyperparameter Tuning - Raw Data\n",
    "fig, axes = plt.subplots(1, 4, figsize=(22, 5))\n",
    "fig.suptitle('Hierarchical Clustering Hyperparameter Tuning Results - Raw Data', fontsize=16, y=1.02)\n",
    "\n",
    "for idx, linkage_method in enumerate(linkage_methods):\n",
    "    # Filter data for this linkage method\n",
    "    data_subset = hierarchical_tuning_df[hierarchical_tuning_df['linkage'] == linkage_method]\n",
    "    \n",
    "    # Plot Silhouette Score\n",
    "    axes[idx].plot(data_subset['n_clusters'], data_subset['validate_silhouette'], \n",
    "                   marker='o', linewidth=2, markersize=8, label='Silhouette (higher better)')\n",
    "    axes[idx].set_xlabel('Number of Clusters', fontsize=11)\n",
    "    axes[idx].set_ylabel('Validation Silhouette Score', fontsize=11)\n",
    "    axes[idx].set_title(f'{linkage_method.capitalize()} Linkage', fontsize=13, fontweight='bold')\n",
    "    axes[idx].grid(True, alpha=0.3)\n",
    "    axes[idx].set_xticks(n_clusters_range)\n",
    "    \n",
    "    # Add Davies-Bouldin on secondary axis (inverted scale)\n",
    "    ax2 = axes[idx].twinx()\n",
    "    ax2.plot(data_subset['n_clusters'], data_subset['validate_davies_bouldin'], \n",
    "            marker='s', color='orange', linewidth=2, markersize=8, \n",
    "            label='Davies-Bouldin (lower better)', alpha=0.7)\n",
    "    ax2.set_ylabel('Validation Davies-Bouldin Index', fontsize=11, color='orange')\n",
    "    ax2.tick_params(axis='y', labelcolor='orange')\n",
    "    \n",
    "    # Combine legends\n",
    "    lines1, labels1 = axes[idx].get_legend_handles_labels()\n",
    "    lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "    axes[idx].legend(lines1 + lines2, labels1 + labels2, loc='best', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Comparison heatmap\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 5))\n",
    "fig.suptitle('Hierarchical Clustering: Linkage Method Comparison Heatmap - Raw Data', fontsize=15)\n",
    "\n",
    "# Silhouette Score heatmap\n",
    "sil_pivot = hierarchical_tuning_df.pivot(index='linkage', columns='n_clusters', values='validate_silhouette')\n",
    "sns.heatmap(sil_pivot, annot=True, fmt='.3f', cmap='RdYlGn', ax=axes[0], \n",
    "            cbar_kws={'label': 'Silhouette Score'}, vmin=0, vmax=1)\n",
    "axes[0].set_title('Validation Silhouette Score', fontsize=13)\n",
    "axes[0].set_xlabel('Number of Clusters')\n",
    "axes[0].set_ylabel('Linkage Method')\n",
    "\n",
    "# Davies-Bouldin Index heatmap (lower is better, so reverse colormap)\n",
    "db_pivot = hierarchical_tuning_df.pivot(index='linkage', columns='n_clusters', values='validate_davies_bouldin')\n",
    "sns.heatmap(db_pivot, annot=True, fmt='.3f', cmap='RdYlGn_r', ax=axes[1],\n",
    "            cbar_kws={'label': 'Davies-Bouldin Index'})\n",
    "axes[1].set_title('Validation Davies-Bouldin Index', fontsize=13)\n",
    "axes[1].set_xlabel('Number of Clusters')\n",
    "axes[1].set_ylabel('Linkage Method')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad210bc",
   "metadata": {},
   "source": [
    "### 7.2 Hierarchical Hyperparameter Tuning - Z-Scored Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6be559f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hierarchical Clustering Comprehensive Hyperparameter Tuning - Z-Scored Data\n",
    "print(\"=\"*80)\n",
    "print(\"HIERARCHICAL CLUSTERING COMPREHENSIVE HYPERPARAMETER TUNING - Z-SCORED DATA\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Define parameter grid\n",
    "linkage_methods_z = ['ward', 'complete', 'average', 'single']\n",
    "n_clusters_range_z = list(range(2, 11))\n",
    "\n",
    "hierarchical_tuning_results_z = []\n",
    "\n",
    "print(\"\\nTesting combinations of linkage methods and n_clusters...\")\n",
    "print(\"(This may take a moment)\\n\")\n",
    "\n",
    "for linkage_method in linkage_methods_z:\n",
    "    # Compute linkage matrix\n",
    "    print(f\"Computing {linkage_method} linkage...\")\n",
    "    linkage_matrix_z = linkage(X_train_z, method=linkage_method)\n",
    "    \n",
    "    for n_clusters in n_clusters_range_z:\n",
    "        # Cut dendrogram at specific n_clusters\n",
    "        cluster_labels_train_z = fcluster(linkage_matrix_z, n_clusters, criterion='maxclust') - 1\n",
    "        \n",
    "        # Compute cluster centers for prediction\n",
    "        cluster_centers_z = []\n",
    "        for i in range(n_clusters):\n",
    "            cluster_mask = cluster_labels_train_z == i\n",
    "            if np.sum(cluster_mask) > 0:  # Check if cluster has points\n",
    "                center = X_train_z[cluster_mask].mean(axis=0)\n",
    "                cluster_centers_z.append(center)\n",
    "        \n",
    "        if len(cluster_centers_z) < n_clusters:\n",
    "            print(f\"  Warning: {linkage_method} with n_clusters={n_clusters} produced {len(cluster_centers_z)} clusters\")\n",
    "            continue\n",
    "            \n",
    "        cluster_centers_z = np.array(cluster_centers_z)\n",
    "        \n",
    "        # Assign validation points to nearest cluster center\n",
    "        cluster_labels_validate_z = cdist(X_validate_z, cluster_centers_z).argmin(axis=1)\n",
    "        \n",
    "        # Check if we have at least 2 unique clusters in both train and validate\n",
    "        n_train_clusters_z = len(np.unique(cluster_labels_train_z))\n",
    "        n_validate_clusters_z = len(np.unique(cluster_labels_validate_z))\n",
    "        \n",
    "        if n_train_clusters_z < 2 or n_validate_clusters_z < 2:\n",
    "            print(f\"  Skipping: {linkage_method} with n_clusters={n_clusters} - insufficient clusters (train={n_train_clusters_z}, val={n_validate_clusters_z})\")\n",
    "            continue\n",
    "        \n",
    "        # Calculate metrics\n",
    "        train_sil_z = silhouette_score(X_train_z, cluster_labels_train_z)\n",
    "        train_db_z = davies_bouldin_score(X_train_z, cluster_labels_train_z)\n",
    "        \n",
    "        validate_sil_z = silhouette_score(X_validate_z, cluster_labels_validate_z)\n",
    "        validate_db_z = davies_bouldin_score(X_validate_z, cluster_labels_validate_z)\n",
    "        \n",
    "        hierarchical_tuning_results_z.append({\n",
    "            'linkage': linkage_method,\n",
    "            'n_clusters': n_clusters,\n",
    "            'train_silhouette': train_sil_z,\n",
    "            'train_davies_bouldin': train_db_z,\n",
    "            'validate_silhouette': validate_sil_z,\n",
    "            'validate_davies_bouldin': validate_db_z\n",
    "        })\n",
    "\n",
    "# Convert to DataFrame\n",
    "hierarchical_tuning_df_z = pd.DataFrame(hierarchical_tuning_results_z)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TUNING RESULTS SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Find best parameters\n",
    "best_hierarchical_z = hierarchical_tuning_df_z.loc[hierarchical_tuning_df_z['validate_silhouette'].idxmax()]\n",
    "\n",
    "print(f\"\\nBest Parameters (by Validation Silhouette Score):\")\n",
    "print(f\"  Linkage Method = '{best_hierarchical_z['linkage']}'\")\n",
    "print(f\"  n_clusters = {int(best_hierarchical_z['n_clusters'])}\")\n",
    "print(f\"\\nExpected Performance:\")\n",
    "print(f\"  Train Silhouette: {best_hierarchical_z['train_silhouette']:.4f}\")\n",
    "print(f\"  Train Davies-Bouldin: {best_hierarchical_z['train_davies_bouldin']:.4f}\")\n",
    "print(f\"  Validate Silhouette: {best_hierarchical_z['validate_silhouette']:.4f}\")\n",
    "print(f\"  Validate Davies-Bouldin: {best_hierarchical_z['validate_davies_bouldin']:.4f}\")\n",
    "\n",
    "# Show top 10 configurations\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"TOP 10 CONFIGURATIONS (by Validation Silhouette Score):\")\n",
    "print(f\"{'='*80}\")\n",
    "top_hierarchical_z = hierarchical_tuning_df_z.nlargest(10, 'validate_silhouette')[['linkage', 'n_clusters', 'train_silhouette', 'validate_silhouette', 'train_davies_bouldin', 'validate_davies_bouldin']]\n",
    "print(top_hierarchical_z.to_string(index=False))\n",
    "\n",
    "# Analysis by linkage method\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"PERFORMANCE COMPARISON BY LINKAGE METHOD:\")\n",
    "print(f\"{'='*80}\\n\")\n",
    "linkage_comparison_z = hierarchical_tuning_df_z.groupby('linkage').agg({\n",
    "    'validate_silhouette': ['mean', 'std', 'max'],\n",
    "    'validate_davies_bouldin': ['mean', 'std', 'min']\n",
    "}).round(4)\n",
    "print(linkage_comparison_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c387eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of Hierarchical Hyperparameter Tuning - Z-Scored Data\n",
    "fig, axes = plt.subplots(1, 4, figsize=(22, 5))\n",
    "fig.suptitle('Hierarchical Clustering Hyperparameter Tuning Results - Z-Scored Data', fontsize=16, y=1.02)\n",
    "\n",
    "for idx, linkage_method in enumerate(linkage_methods_z):\n",
    "    # Filter data for this linkage method\n",
    "    data_subset_z = hierarchical_tuning_df_z[hierarchical_tuning_df_z['linkage'] == linkage_method]\n",
    "    \n",
    "    # Plot Silhouette Score\n",
    "    axes[idx].plot(data_subset_z['n_clusters'], data_subset_z['validate_silhouette'], \n",
    "                   marker='o', linewidth=2, markersize=8, label='Silhouette (higher better)')\n",
    "    axes[idx].set_xlabel('Number of Clusters', fontsize=11)\n",
    "    axes[idx].set_ylabel('Validation Silhouette Score', fontsize=11)\n",
    "    axes[idx].set_title(f'{linkage_method.capitalize()} Linkage', fontsize=13, fontweight='bold')\n",
    "    axes[idx].grid(True, alpha=0.3)\n",
    "    axes[idx].set_xticks(n_clusters_range_z)\n",
    "    \n",
    "    # Add Davies-Bouldin on secondary axis (inverted scale)\n",
    "    ax2 = axes[idx].twinx()\n",
    "    ax2.plot(data_subset_z['n_clusters'], data_subset_z['validate_davies_bouldin'], \n",
    "            marker='s', color='orange', linewidth=2, markersize=8, \n",
    "            label='Davies-Bouldin (lower better)', alpha=0.7)\n",
    "    ax2.set_ylabel('Validation Davies-Bouldin Index', fontsize=11, color='orange')\n",
    "    ax2.tick_params(axis='y', labelcolor='orange')\n",
    "    \n",
    "    # Combine legends\n",
    "    lines1, labels1 = axes[idx].get_legend_handles_labels()\n",
    "    lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "    axes[idx].legend(lines1 + lines2, labels1 + labels2, loc='best', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Comparison heatmap\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 5))\n",
    "fig.suptitle('Hierarchical Clustering: Linkage Method Comparison Heatmap - Z-Scored Data', fontsize=15)\n",
    "\n",
    "# Silhouette Score heatmap\n",
    "sil_pivot_z = hierarchical_tuning_df_z.pivot(index='linkage', columns='n_clusters', values='validate_silhouette')\n",
    "sns.heatmap(sil_pivot_z, annot=True, fmt='.3f', cmap='RdYlGn', ax=axes[0], \n",
    "            cbar_kws={'label': 'Silhouette Score'}, vmin=0, vmax=1)\n",
    "axes[0].set_title('Validation Silhouette Score', fontsize=13)\n",
    "axes[0].set_xlabel('Number of Clusters')\n",
    "axes[0].set_ylabel('Linkage Method')\n",
    "\n",
    "# Davies-Bouldin Index heatmap (lower is better, so reverse colormap)\n",
    "db_pivot_z = hierarchical_tuning_df_z.pivot(index='linkage', columns='n_clusters', values='validate_davies_bouldin')\n",
    "sns.heatmap(db_pivot_z, annot=True, fmt='.3f', cmap='RdYlGn_r', ax=axes[1],\n",
    "            cbar_kws={'label': 'Davies-Bouldin Index'})\n",
    "axes[1].set_title('Validation Davies-Bouldin Index', fontsize=13)\n",
    "axes[1].set_xlabel('Number of Clusters')\n",
    "axes[1].set_ylabel('Linkage Method')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57d96ec",
   "metadata": {},
   "source": [
    "### 6.2 K-Means Hyperparameter Tuning - Z-Scored Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015fce0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show plots for both sets of data side by side for comparison\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "datasets = [\n",
    "    (X_train_scaled, df_train['cluster'], 'Train - Original'),\n",
    "    (X_validate_scaled, df_validate['cluster'], 'Validate - Original'),\n",
    "    (X_test_scaled, df_test['cluster'], 'Test - Original'),\n",
    "    (X_train_z, df_train_z['cluster'], 'Train - Z-Scored'),\n",
    "    (X_validate_z, df_validate_z['cluster'], 'Validate - Z-Scored'),\n",
    "    (X_test_z, df_test_z['cluster'], 'Test - Z-Scored')\n",
    "]\n",
    "\n",
    "for ax, (X, clusters, title) in zip(axes.flatten(), datasets):\n",
    "    scatter = ax.scatter(X[:, 0], X[:, 1], c=clusters, cmap='viridis', alpha=0.6, s=30)\n",
    "    if 'Z-Scored' in title:\n",
    "        ax.scatter(kmeans_z.cluster_centers_[:, 0], kmeans_z.cluster_centers_[:, 1], \n",
    "                   c='red', marker='X', s=200, edgecolors='black', linewidths=2, label='Centroids')\n",
    "    else:\n",
    "        ax.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], \n",
    "                   c='red', marker='X', s=200, edgecolors='black', linewidths=2, label='Centroids')\n",
    "    ax.set_xlabel(f'Feature 1: {feature_cols[0]}')\n",
    "    ax.set_ylabel(f'Feature 2: {feature_cols[1]}')\n",
    "    ax.set_title(title)\n",
    "    ax.legend()\n",
    "    plt.colorbar(scatter, ax=ax, label='Cluster')\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3787e58b",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. K-Means Clustering on Raw Data\n",
    "\n",
    "### 5.1 Data Preparation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1aaf3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# K Means clustering on base metrics\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score\n",
    "\n",
    "# Prepare data - exclude merchant_id column for clustering\n",
    "feature_cols = [col for col in df_train.columns if col != 'merchant_id']\n",
    "X_train_scaled = df_train[feature_cols].values\n",
    "X_validate_scaled = df_validate[feature_cols].values\n",
    "X_test_scaled = df_test[feature_cols].values\n",
    "\n",
    "print(f\"Training data shape: {X_train_scaled.shape}\")\n",
    "print(f\"Features used: {feature_cols}\")\n",
    "print(f\"Number of merchants - Train: {len(df_train)}, Validate: {len(df_validate)}, Test: {len(df_test)}\")\n",
    "print(f\"\\nUsing raw data without scaling\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2812dbe3",
   "metadata": {},
   "source": [
    "### 3.2 Elbow Method & Silhouette Analysis (k=2-10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6c0bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elbow Method - Find optimal number of clusters\n",
    "inertias = []\n",
    "silhouette_scores = []\n",
    "k_range = range(2, 11)\n",
    "\n",
    "for k in k_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    kmeans.fit(X_train_scaled)\n",
    "    inertias.append(kmeans.inertia_)\n",
    "    silhouette_scores.append(silhouette_score(X_train_scaled, kmeans.labels_))\n",
    "\n",
    "# Plot results\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Elbow plot\n",
    "ax1.plot(k_range, inertias, 'bo-')\n",
    "ax1.set_xlabel('Number of Clusters (k)')\n",
    "ax1.set_ylabel('Inertia (Within-cluster sum of squares)')\n",
    "ax1.set_title('Elbow Method For Optimal k')\n",
    "ax1.grid(True)\n",
    "\n",
    "# Silhouette plot\n",
    "ax2.plot(k_range, silhouette_scores, 'ro-')\n",
    "ax2.set_xlabel('Number of Clusters (k)')\n",
    "ax2.set_ylabel('Silhouette Score')\n",
    "ax2.set_title('Silhouette Score vs Number of Clusters')\n",
    "ax2.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nSilhouette Scores:\")\n",
    "for k, score in zip(k_range, silhouette_scores):\n",
    "    print(f\"k={k}: {score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126569f2",
   "metadata": {},
   "source": [
    "### 3.3 Fit Model with Optimal k (Using Tuned Hyperparameters)\n",
    "\n",
    "**Note**: Run Section 6.1 (K-Means Hyperparameter Tuning) first to populate optimal parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6dd830a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit K-Means with optimal hyperparameters from tuning (Section 6.1)\n",
    "# If best_kmeans doesn't exist, run Section 6.1 first\n",
    "try:\n",
    "    optimal_k = int(best_kmeans['k'])\n",
    "    optimal_init = best_kmeans['init']\n",
    "    optimal_n_init = int(best_kmeans['n_init'])\n",
    "    print(f\"Using tuned parameters: k={optimal_k}, init='{optimal_init}', n_init={optimal_n_init}\")\n",
    "except (NameError, KeyError):\n",
    "    print(\"Warning: best_kmeans not found. Run Section 6.1 first or using fallback k=5\")\n",
    "    optimal_k = 5\n",
    "    optimal_init = 'k-means++'\n",
    "    optimal_n_init = 10\n",
    "\n",
    "kmeans = KMeans(n_clusters=optimal_k, init=optimal_init, n_init=optimal_n_init, random_state=42, max_iter=300)\n",
    "kmeans.fit(X_train_scaled)\n",
    "\n",
    "# Get cluster labels\n",
    "df_train['cluster'] = kmeans.labels_\n",
    "df_validate['cluster'] = kmeans.predict(X_validate_scaled)\n",
    "df_test['cluster'] = kmeans.predict(X_test_scaled)\n",
    "\n",
    "# Evaluation metrics\n",
    "train_silhouette = silhouette_score(X_train_scaled, df_train['cluster'])\n",
    "train_davies_bouldin = davies_bouldin_score(X_train_scaled, df_train['cluster'])\n",
    "\n",
    "print(f\"\\nK-Means with {optimal_k} clusters\")\n",
    "print(f\"Training Set Metrics:\")\n",
    "print(f\"  Silhouette Score: {train_silhouette:.4f} (higher is better, range: -1 to 1)\")\n",
    "print(f\"  Davies-Bouldin Index: {train_davies_bouldin:.4f} (lower is better)\")\n",
    "print(f\"  Inertia: {kmeans.inertia_:.2f}\")\n",
    "\n",
    "print(f\"\\nCluster Distribution (Train):\")\n",
    "print(df_train['cluster'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d8ae6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize clusters (2D projection using first 2 features)\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "datasets = [\n",
    "    (X_train_scaled, df_train['cluster'], 'Train'),\n",
    "    (X_validate_scaled, df_validate['cluster'], 'Validate'),\n",
    "    (X_test_scaled, df_test['cluster'], 'Test')\n",
    "]\n",
    "\n",
    "for ax, (X, clusters, title) in zip(axes, datasets):\n",
    "    scatter = ax.scatter(X[:, 0], X[:, 1], c=clusters, cmap='viridis', alpha=0.6, s=30)\n",
    "    ax.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], \n",
    "               c='red', marker='X', s=200, edgecolors='black', linewidths=2, label='Centroids')\n",
    "    ax.set_xlabel(f'Feature 1: {feature_cols[0]}')\n",
    "    ax.set_ylabel(f'Feature 2: {feature_cols[1]}')\n",
    "    ax.set_title(f'{title} Set - {optimal_k} Clusters')\n",
    "    ax.legend()\n",
    "    plt.colorbar(scatter, ax=ax, label='Cluster')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a9c6c4",
   "metadata": {},
   "source": [
    "### 3.4 Cluster Analysis & Statistics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7af3037",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze cluster characteristics\n",
    "print(\"=== CLUSTER CHARACTERISTICS ===\\n\")\n",
    "\n",
    "# Use raw data (no scaling was applied)\n",
    "df_train_with_features = pd.DataFrame(X_train_scaled, columns=feature_cols)\n",
    "df_train_with_features['cluster'] = df_train['cluster'].values\n",
    "\n",
    "# Calculate statistics per cluster\n",
    "cluster_stats = df_train_with_features.groupby('cluster').agg(['mean', 'std', 'count'])\n",
    "\n",
    "print(\"Cluster Statistics (mean values):\")\n",
    "print(cluster_stats.xs('mean', level=1, axis=1))\n",
    "\n",
    "print(\"\\n\\nCluster Sizes:\")\n",
    "print(df_train_with_features['cluster'].value_counts().sort_index())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8bcf96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# score the clusters on validate and test sets\n",
    "validate_silhouette = silhouette_score(X_validate_scaled, df_validate['cluster'])\n",
    "validate_davies_bouldin = davies_bouldin_score(X_validate_scaled, df_validate['cluster'])\n",
    "\n",
    "print(f\"Validation Set Metrics:\")\n",
    "print(f\"  Silhouette Score: {validate_silhouette:.4f} (higher is better, range: -1 to 1)\")\n",
    "print(f\"  Davies-Bouldin Index: {validate_davies_bouldin:.4f} (lower is better)\")\n",
    "\n",
    "test_silhouette = silhouette_score(X_test_scaled, df_test['cluster'])\n",
    "test_davies_bouldin = davies_bouldin_score(X_test_scaled, df_test['cluster'])\n",
    "print(f\"\\nTest Set Metrics:\")\n",
    "print(f\"  Silhouette Score: {test_silhouette:.4f} (higher is better, range: -1 to 1)\")\n",
    "print(f\"  Davies-Bouldin Index: {test_davies_bouldin:.4f} (lower is better)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf63a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigate the features in detail\n",
    "print(\"=== FEATURE INVESTIGATION ===\\n\")\n",
    "\n",
    "print(\"Column names in training data:\")\n",
    "print(df_train.columns.tolist())\n",
    "print(f\"\\nShape: {df_train.shape}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Feature columns used for clustering:\")\n",
    "print(feature_cols)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Sample of raw data (first 10 merchants):\")\n",
    "print(df_train.head(10))\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Descriptive statistics for all features:\")\n",
    "print(df_train[feature_cols].describe())\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Check for any negative values:\")\n",
    "for col in feature_cols:\n",
    "    neg_count = (df_train[col] < 0).sum()\n",
    "    if neg_count > 0:\n",
    "        print(f\"{col}: {neg_count} negative values (min: {df_train[col].min():.4f})\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Check for zero/non-zero patterns:\")\n",
    "for col in feature_cols:\n",
    "    zero_count = (df_train[col] == 0).sum()\n",
    "    nonzero_count = (df_train[col] != 0).sum()\n",
    "    print(f\"{col}: {zero_count} zeros, {nonzero_count} non-zeros\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d6242e",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. K-Means Clustering on Z-Scored Data\n",
    "\n",
    "Now clustering on the pre-z-scored datasets: `*_base_zscored.csv`\n",
    "\n",
    "### 6.1 Load Z-Scored Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e537320",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load z-scored datasets\n",
    "df_train_z = pd.read_csv('base_features/df_train_base_zscored.csv')\n",
    "df_validate_z = pd.read_csv('base_features/df_validate_base_zscored.csv')\n",
    "df_test_z = pd.read_csv('base_features/df_test_base_zscored.csv')\n",
    "\n",
    "print(f\"Loaded z-scored datasets:\")\n",
    "print(f\"  Train: {df_train_z.shape}\")\n",
    "print(f\"  Validate: {df_validate_z.shape}\")\n",
    "print(f\"  Test: {df_test_z.shape}\")\n",
    "print(f\"\\nColumns: {df_train_z.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9167a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for and handle missing values\n",
    "print(\"=== DATA QUALITY CHECK (Z-SCORED) ===\\n\")\n",
    "\n",
    "for name, df in [('Train', df_train_z), ('Validate', df_validate_z), ('Test', df_test_z)]:\n",
    "    null_counts = df.isnull().sum()\n",
    "    if null_counts.sum() > 0:\n",
    "        print(f\"{name} dataset - Missing values:\")\n",
    "        print(null_counts[null_counts > 0])\n",
    "        print()\n",
    "\n",
    "# Fill NaN values with 0\n",
    "print(\"Filling NaN values with 0...\")\n",
    "df_train_z = df_train_z.fillna(0)\n",
    "df_validate_z = df_validate_z.fillna(0)\n",
    "df_test_z = df_test_z.fillna(0)\n",
    "\n",
    "# Check for and handle infinite values\n",
    "print(\"\\nChecking for infinite values...\")\n",
    "for name, df in [('Train', df_train_z), ('Validate', df_validate_z), ('Test', df_test_z)]:\n",
    "    inf_mask = np.isinf(df.select_dtypes(include=[np.number])).any(axis=1)\n",
    "    if inf_mask.sum() > 0:\n",
    "        print(f\"{name}: {inf_mask.sum()} rows with infinite values\")\n",
    "\n",
    "# Replace infinite values with 0\n",
    "df_train_z = df_train_z.replace([np.inf, -np.inf], 0)\n",
    "df_validate_z = df_validate_z.replace([np.inf, -np.inf], 0)\n",
    "df_test_z = df_test_z.replace([np.inf, -np.inf], 0)\n",
    "\n",
    "print(\"\\nData cleaned successfully!\")\n",
    "print(f\"Train: {df_train_z.shape}, Validate: {df_validate_z.shape}, Test: {df_test_z.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919230f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data - data is already z-scored, so no need to scale again\n",
    "feature_cols_z = [col for col in df_train_z.columns if col != 'merchant_id']\n",
    "X_train_z = df_train_z[feature_cols_z].values\n",
    "X_validate_z = df_validate_z[feature_cols_z].values\n",
    "X_test_z = df_test_z[feature_cols_z].values\n",
    "\n",
    "print(f\"Training data shape: {X_train_z.shape}\")\n",
    "print(f\"Features used: {feature_cols_z}\")\n",
    "print(f\"Number of merchants - Train: {len(df_train_z)}, Validate: {len(df_validate_z)}, Test: {len(df_test_z)}\")\n",
    "print(f\"\\nData is pre-z-scored - using directly without StandardScaler\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35e9c72",
   "metadata": {},
   "source": [
    "### 4.2 Elbow Method & Silhouette Analysis (k=2-10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b6f6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elbow Method - Find optimal number of clusters (Z-scored data)\n",
    "inertias_z = []\n",
    "silhouette_scores_z = []\n",
    "k_range_z = range(2, 11)\n",
    "\n",
    "for k in k_range_z:\n",
    "    kmeans_z = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    kmeans_z.fit(X_train_z)\n",
    "    inertias_z.append(kmeans_z.inertia_)\n",
    "    silhouette_scores_z.append(silhouette_score(X_train_z, kmeans_z.labels_))\n",
    "\n",
    "# Plot results\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Elbow plot\n",
    "ax1.plot(k_range_z, inertias_z, 'bo-')\n",
    "ax1.set_xlabel('Number of Clusters (k)')\n",
    "ax1.set_ylabel('Inertia (Within-cluster sum of squares)')\n",
    "ax1.set_title('Elbow Method For Optimal k (Z-Scored Data)')\n",
    "ax1.grid(True)\n",
    "\n",
    "# Silhouette plot\n",
    "ax2.plot(k_range_z, silhouette_scores_z, 'ro-')\n",
    "ax2.set_xlabel('Number of Clusters (k)')\n",
    "ax2.set_ylabel('Silhouette Score')\n",
    "ax2.set_title('Silhouette Score vs Number of Clusters (Z-Scored Data)')\n",
    "ax2.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nSilhouette Scores (Z-Scored):\")\n",
    "for k, score in zip(k_range_z, silhouette_scores_z):\n",
    "    print(f\"k={k}: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2ba40f",
   "metadata": {},
   "source": [
    "### 4.3 Fit Model with Optimal k (Using Tuned Hyperparameters)\n",
    "\n",
    "**Note**: Run Section 6.2 (K-Means Hyperparameter Tuning - Z-Scored) first to populate optimal parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0675b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit K-Means with optimal hyperparameters from tuning (Section 6.2)\n",
    "# If best_kmeans_z doesn't exist, run Section 6.2 first\n",
    "try:\n",
    "    optimal_k_z = int(best_kmeans_z['k'])\n",
    "    optimal_init_z = best_kmeans_z['init']\n",
    "    optimal_n_init_z = int(best_kmeans_z['n_init'])\n",
    "    print(f\"Using tuned parameters: k={optimal_k_z}, init='{optimal_init_z}', n_init={optimal_n_init_z}\")\n",
    "except (NameError, KeyError):\n",
    "    print(\"Warning: best_kmeans_z not found. Run Section 6.2 first or using fallback k=5\")\n",
    "    optimal_k_z = 5\n",
    "    optimal_init_z = 'k-means++'\n",
    "    optimal_n_init_z = 10\n",
    "\n",
    "kmeans_z = KMeans(n_clusters=optimal_k_z, init=optimal_init_z, n_init=optimal_n_init_z, random_state=42, max_iter=300)\n",
    "kmeans_z.fit(X_train_z)\n",
    "\n",
    "# Get cluster labels\n",
    "df_train_z['cluster'] = kmeans_z.labels_\n",
    "df_validate_z['cluster'] = kmeans_z.predict(X_validate_z)\n",
    "df_test_z['cluster'] = kmeans_z.predict(X_test_z)\n",
    "\n",
    "# Evaluation metrics\n",
    "train_silhouette_z = silhouette_score(X_train_z, df_train_z['cluster'])\n",
    "train_davies_bouldin_z = davies_bouldin_score(X_train_z, df_train_z['cluster'])\n",
    "\n",
    "print(f\"\\nK-Means with {optimal_k_z} clusters (Z-Scored Data)\")\n",
    "print(f\"Training Set Metrics:\")\n",
    "print(f\"  Silhouette Score: {train_silhouette_z:.4f} (higher is better, range: -1 to 1)\")\n",
    "print(f\"  Davies-Bouldin Index: {train_davies_bouldin_z:.4f} (lower is better)\")\n",
    "print(f\"  Inertia: {kmeans_z.inertia_:.2f}\")\n",
    "\n",
    "print(f\"\\nCluster Distribution (Train):\")\n",
    "print(df_train_z['cluster'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b773f020",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize clusters (Z-scored data)\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "datasets_z = [\n",
    "    (X_train_z, df_train_z['cluster'], 'Train'),\n",
    "    (X_validate_z, df_validate_z['cluster'], 'Validate'),\n",
    "    (X_test_z, df_test_z['cluster'], 'Test')\n",
    "]\n",
    "\n",
    "for ax, (X, clusters, title) in zip(axes, datasets_z):\n",
    "    scatter = ax.scatter(X[:, 0], X[:, 1], c=clusters, cmap='viridis', alpha=0.6, s=30)\n",
    "    ax.scatter(kmeans_z.cluster_centers_[:, 0], kmeans_z.cluster_centers_[:, 1], \n",
    "               c='red', marker='X', s=200, edgecolors='black', linewidths=2, label='Centroids')\n",
    "    ax.set_xlabel(f'Feature 1: {feature_cols_z[0]}')\n",
    "    ax.set_ylabel(f'Feature 2: {feature_cols_z[1]}')\n",
    "    ax.set_title(f'{title} Set - {optimal_k_z} Clusters (Z-Scored)')\n",
    "    ax.legend()\n",
    "    plt.colorbar(scatter, ax=ax, label='Cluster')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46b5337",
   "metadata": {},
   "source": [
    "### 4.4 Cluster Analysis & Statistics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d9c532",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze cluster characteristics (Z-scored data)\n",
    "print(\"=== CLUSTER CHARACTERISTICS (Z-SCORED DATA) ===\\n\")\n",
    "\n",
    "df_train_z_features = pd.DataFrame(X_train_z, columns=feature_cols_z)\n",
    "df_train_z_features['cluster'] = df_train_z['cluster'].values\n",
    "df_train_z_features['merchant_id'] = df_train_z['merchant_id'].values\n",
    "\n",
    "# Calculate statistics per cluster\n",
    "cluster_stats_z = df_train_z_features.groupby('cluster').agg(['mean', 'std', 'count'])\n",
    "\n",
    "print(\"Cluster Statistics (mean values):\")\n",
    "print(cluster_stats_z.xs('mean', level=1, axis=1))\n",
    "\n",
    "print(\"\\n\\nCluster Sizes:\")\n",
    "print(df_train_z_features['cluster'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910c8bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score the clusters on validate and test sets (Z-scored data)\n",
    "validate_silhouette_z = silhouette_score(X_validate_z, df_validate_z['cluster'])\n",
    "validate_davies_bouldin_z = davies_bouldin_score(X_validate_z, df_validate_z['cluster'])\n",
    "\n",
    "print(f\"Validation Set Metrics (Z-Scored):\")\n",
    "print(f\"  Silhouette Score: {validate_silhouette_z:.4f} (higher is better, range: -1 to 1)\")\n",
    "print(f\"  Davies-Bouldin Index: {validate_davies_bouldin_z:.4f} (lower is better)\")\n",
    "\n",
    "test_silhouette_z = silhouette_score(X_test_z, df_test_z['cluster'])\n",
    "test_davies_bouldin_z = davies_bouldin_score(X_test_z, df_test_z['cluster'])\n",
    "print(f\"\\nTest Set Metrics (Z-Scored):\")\n",
    "print(f\"  Silhouette Score: {test_silhouette_z:.4f} (higher is better, range: -1 to 1)\")\n",
    "print(f\"  Davies-Bouldin Index: {test_davies_bouldin_z:.4f} (lower is better)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f4a868",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Extended K-Value Testing (k=2 to k=15)\n",
    "\n",
    "Comprehensive evaluation of different k values to determine optimal cluster count.\n",
    "\n",
    "### 7.1 Compute Metrics for Multiple k Values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f43bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test for a wider range of k values with comprehensive metrics\n",
    "# Testing k from 2 to 15 for both raw and z-scored data\n",
    "\n",
    "k_range_extended = range(2, 16)\n",
    "\n",
    "# Store results for raw data\n",
    "results_raw = {\n",
    "    'k': [],\n",
    "    'train_silhouette': [],\n",
    "    'train_davies_bouldin': [],\n",
    "    'validate_silhouette': [],\n",
    "    'validate_davies_bouldin': [],\n",
    "    'inertia': []\n",
    "}\n",
    "\n",
    "# Store results for z-scored data\n",
    "results_zscored = {\n",
    "    'k': [],\n",
    "    'train_silhouette': [],\n",
    "    'train_davies_bouldin': [],\n",
    "    'validate_silhouette': [],\n",
    "    'validate_davies_bouldin': [],\n",
    "    'inertia': []\n",
    "}\n",
    "\n",
    "print(\"Testing k values from 2 to 15...\")\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "\n",
    "for k in k_range_extended:\n",
    "    # Raw data clustering\n",
    "    kmeans_test = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    kmeans_test.fit(X_train_scaled)\n",
    "    train_labels = kmeans_test.labels_\n",
    "    validate_labels = kmeans_test.predict(X_validate_scaled)\n",
    "    \n",
    "    results_raw['k'].append(k)\n",
    "    results_raw['inertia'].append(kmeans_test.inertia_)\n",
    "    results_raw['train_silhouette'].append(silhouette_score(X_train_scaled, train_labels))\n",
    "    results_raw['train_davies_bouldin'].append(davies_bouldin_score(X_train_scaled, train_labels))\n",
    "    results_raw['validate_silhouette'].append(silhouette_score(X_validate_scaled, validate_labels))\n",
    "    results_raw['validate_davies_bouldin'].append(davies_bouldin_score(X_validate_scaled, validate_labels))\n",
    "    \n",
    "    # Z-scored data clustering\n",
    "    kmeans_test_z = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    kmeans_test_z.fit(X_train_z)\n",
    "    train_labels_z = kmeans_test_z.labels_\n",
    "    validate_labels_z = kmeans_test_z.predict(X_validate_z)\n",
    "    \n",
    "    results_zscored['k'].append(k)\n",
    "    results_zscored['inertia'].append(kmeans_test_z.inertia_)\n",
    "    results_zscored['train_silhouette'].append(silhouette_score(X_train_z, train_labels_z))\n",
    "    results_zscored['train_davies_bouldin'].append(davies_bouldin_score(X_train_z, train_labels_z))\n",
    "    results_zscored['validate_silhouette'].append(silhouette_score(X_validate_z, validate_labels_z))\n",
    "    results_zscored['validate_davies_bouldin'].append(davies_bouldin_score(X_validate_z, validate_labels_z))\n",
    "\n",
    "print(\"Completed testing all k values!\")\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"\\nRAW DATA RESULTS:\")\n",
    "import pandas as pd\n",
    "df_results_raw = pd.DataFrame(results_raw)\n",
    "print(df_results_raw.to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"\\nZ-SCORED DATA RESULTS:\")\n",
    "df_results_zscored = pd.DataFrame(results_zscored)\n",
    "print(df_results_zscored.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7f94aa",
   "metadata": {},
   "source": [
    "### 6.2 Visualization & Optimal k Recommendations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e8ec01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize metrics across different k values\n",
    "fig, axes = plt.subplots(2, 3, figsize=(20, 12))\n",
    "\n",
    "# Raw data plots\n",
    "axes[0, 0].plot(results_raw['k'], results_raw['inertia'], 'bo-', linewidth=2, markersize=8)\n",
    "axes[0, 0].set_xlabel('Number of Clusters (k)', fontsize=12)\n",
    "axes[0, 0].set_ylabel('Inertia', fontsize=12)\n",
    "axes[0, 0].set_title('Raw Data: Elbow Method', fontsize=14, fontweight='bold')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[0, 1].plot(results_raw['k'], results_raw['train_silhouette'], 'go-', label='Train', linewidth=2, markersize=8)\n",
    "axes[0, 1].plot(results_raw['k'], results_raw['validate_silhouette'], 'ro-', label='Validate', linewidth=2, markersize=8)\n",
    "axes[0, 1].set_xlabel('Number of Clusters (k)', fontsize=12)\n",
    "axes[0, 1].set_ylabel('Silhouette Score', fontsize=12)\n",
    "axes[0, 1].set_title('Raw Data: Silhouette Score', fontsize=14, fontweight='bold')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "axes[0, 2].plot(results_raw['k'], results_raw['train_davies_bouldin'], 'go-', label='Train', linewidth=2, markersize=8)\n",
    "axes[0, 2].plot(results_raw['k'], results_raw['validate_davies_bouldin'], 'ro-', label='Validate', linewidth=2, markersize=8)\n",
    "axes[0, 2].set_xlabel('Number of Clusters (k)', fontsize=12)\n",
    "axes[0, 2].set_ylabel('Davies-Bouldin Index', fontsize=12)\n",
    "axes[0, 2].set_title('Raw Data: Davies-Bouldin Index (lower is better)', fontsize=14, fontweight='bold')\n",
    "axes[0, 2].legend()\n",
    "axes[0, 2].grid(True, alpha=0.3)\n",
    "\n",
    "# Z-scored data plots\n",
    "axes[1, 0].plot(results_zscored['k'], results_zscored['inertia'], 'bo-', linewidth=2, markersize=8)\n",
    "axes[1, 0].set_xlabel('Number of Clusters (k)', fontsize=12)\n",
    "axes[1, 0].set_ylabel('Inertia', fontsize=12)\n",
    "axes[1, 0].set_title('Z-Scored Data: Elbow Method', fontsize=14, fontweight='bold')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1, 1].plot(results_zscored['k'], results_zscored['train_silhouette'], 'go-', label='Train', linewidth=2, markersize=8)\n",
    "axes[1, 1].plot(results_zscored['k'], results_zscored['validate_silhouette'], 'ro-', label='Validate', linewidth=2, markersize=8)\n",
    "axes[1, 1].set_xlabel('Number of Clusters (k)', fontsize=12)\n",
    "axes[1, 1].set_ylabel('Silhouette Score', fontsize=12)\n",
    "axes[1, 1].set_title('Z-Scored Data: Silhouette Score', fontsize=14, fontweight='bold')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1, 2].plot(results_zscored['k'], results_zscored['train_davies_bouldin'], 'go-', label='Train', linewidth=2, markersize=8)\n",
    "axes[1, 2].plot(results_zscored['k'], results_zscored['validate_davies_bouldin'], 'ro-', label='Validate', linewidth=2, markersize=8)\n",
    "axes[1, 2].set_xlabel('Number of Clusters (k)', fontsize=12)\n",
    "axes[1, 2].set_ylabel('Davies-Bouldin Index', fontsize=12)\n",
    "axes[1, 2].set_title('Z-Scored Data: Davies-Bouldin Index (lower is better)', fontsize=14, fontweight='bold')\n",
    "axes[1, 2].legend()\n",
    "axes[1, 2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Find optimal k based on different criteria\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RECOMMENDED K VALUES:\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Raw data recommendations\n",
    "best_k_raw_sil = results_raw['k'][results_raw['validate_silhouette'].index(max(results_raw['validate_silhouette']))]\n",
    "best_k_raw_db = results_raw['k'][results_raw['validate_davies_bouldin'].index(min(results_raw['validate_davies_bouldin']))]\n",
    "print(f\"\\nRaw Data:\")\n",
    "print(f\"  Best k by Validation Silhouette Score: k={best_k_raw_sil} (score={max(results_raw['validate_silhouette']):.4f})\")\n",
    "print(f\"  Best k by Validation Davies-Bouldin: k={best_k_raw_db} (score={min(results_raw['validate_davies_bouldin']):.4f})\")\n",
    "\n",
    "# Z-scored data recommendations\n",
    "best_k_z_sil = results_zscored['k'][results_zscored['validate_silhouette'].index(max(results_zscored['validate_silhouette']))]\n",
    "best_k_z_db = results_zscored['k'][results_zscored['validate_davies_bouldin'].index(min(results_zscored['validate_davies_bouldin']))]\n",
    "print(f\"\\nZ-Scored Data:\")\n",
    "print(f\"  Best k by Validation Silhouette Score: k={best_k_z_sil} (score={max(results_zscored['validate_silhouette']):.4f})\")\n",
    "print(f\"  Best k by Validation Davies-Bouldin: k={best_k_z_db} (score={min(results_zscored['validate_davies_bouldin']):.4f})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c9227d",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. Hierarchical Clustering\n",
    "\n",
    "Hierarchical clustering builds a tree of clusters (dendrogram) without requiring a pre-specified number of clusters.\n",
    "\n",
    "### 8.1 Hierarchical Clustering on Raw Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e7823d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import dendrogram, linkage, fcluster\n",
    "from scipy.spatial.distance import pdist\n",
    "\n",
    "# Perform hierarchical clustering with different linkage methods\n",
    "linkage_methods = ['ward', 'complete', 'average']\n",
    "\n",
    "# We'll use a sample of the data for dendrogram visualization (dendrograms get messy with too many points)\n",
    "sample_size = 500\n",
    "sample_indices = np.random.choice(len(X_train_scaled), min(sample_size, len(X_train_scaled)), replace=False)\n",
    "X_sample = X_train_scaled[sample_indices]\n",
    "\n",
    "print(f\"Performing hierarchical clustering on sample of {len(X_sample)} merchants\")\n",
    "print(f\"Testing linkage methods: {linkage_methods}\\n\")\n",
    "\n",
    "# Store linkage results\n",
    "linkage_results = {}\n",
    "\n",
    "for method in linkage_methods:\n",
    "    print(f\"Computing {method} linkage...\")\n",
    "    linkage_matrix = linkage(X_sample, method=method)\n",
    "    linkage_results[method] = linkage_matrix\n",
    "\n",
    "print(\"\\nLinkage computation complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1078e82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize dendrograms for different linkage methods\n",
    "fig, axes = plt.subplots(1, 3, figsize=(20, 6))\n",
    "\n",
    "for ax, method in zip(axes, linkage_methods):\n",
    "    dendrogram(linkage_results[method], ax=ax, no_labels=True, color_threshold=0)\n",
    "    ax.set_title(f'Dendrogram - {method.capitalize()} Linkage', fontsize=14, fontweight='bold')\n",
    "    ax.set_xlabel('Sample Index', fontsize=12)\n",
    "    ax.set_ylabel('Distance', fontsize=12)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nDendrograms show the hierarchical structure of clusters.\")\n",
    "print(\"The height of each merge indicates the distance between clusters.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e421eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply hierarchical clustering to full training data with optimal number of clusters\n",
    "# Using Ward linkage (generally performs well and minimizes variance)\n",
    "\n",
    "print(\"=== HIERARCHICAL CLUSTERING (WARD LINKAGE) ===\\n\")\n",
    "\n",
    "# Compute linkage on full training data\n",
    "linkage_train = linkage(X_train_scaled, method='ward')\n",
    "\n",
    "# Cut the dendrogram to get clusters (using optimal_k from K-means)\n",
    "n_clusters_hier = optimal_k\n",
    "hierarchical_labels_train = fcluster(linkage_train, n_clusters_hier, criterion='maxclust')\n",
    "\n",
    "# Assign labels to dataframes\n",
    "df_train['cluster_hierarchical'] = hierarchical_labels_train - 1  # Convert to 0-indexed\n",
    "\n",
    "# Predict on validation and test sets (using nearest cluster center approach)\n",
    "# For hierarchical clustering on new data, we compute linkage with the training data\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "# Compute cluster centers from training data\n",
    "hier_cluster_centers = []\n",
    "for i in range(n_clusters_hier):\n",
    "    cluster_mask = df_train['cluster_hierarchical'] == i\n",
    "    center = X_train_scaled[cluster_mask].mean(axis=0)\n",
    "    hier_cluster_centers.append(center)\n",
    "hier_cluster_centers = np.array(hier_cluster_centers)\n",
    "\n",
    "# Assign validation and test data to nearest cluster center\n",
    "df_validate['cluster_hierarchical'] = cdist(X_validate_scaled, hier_cluster_centers).argmin(axis=1)\n",
    "df_test['cluster_hierarchical'] = cdist(X_test_scaled, hier_cluster_centers).argmin(axis=1)\n",
    "\n",
    "# Evaluate\n",
    "train_silhouette_hier = silhouette_score(X_train_scaled, df_train['cluster_hierarchical'])\n",
    "train_davies_bouldin_hier = davies_bouldin_score(X_train_scaled, df_train['cluster_hierarchical'])\n",
    "validate_silhouette_hier = silhouette_score(X_validate_scaled, df_validate['cluster_hierarchical'])\n",
    "validate_davies_bouldin_hier = davies_bouldin_score(X_validate_scaled, df_validate['cluster_hierarchical'])\n",
    "test_silhouette_hier = silhouette_score(X_test_scaled, df_test['cluster_hierarchical'])\n",
    "test_davies_bouldin_hier = davies_bouldin_score(X_test_scaled, df_test['cluster_hierarchical'])\n",
    "\n",
    "print(f\"Hierarchical Clustering with {n_clusters_hier} clusters (Ward Linkage)\")\n",
    "print(f\"\\nTraining Set Metrics:\")\n",
    "print(f\"  Silhouette Score: {train_silhouette_hier:.4f}\")\n",
    "print(f\"  Davies-Bouldin Index: {train_davies_bouldin_hier:.4f}\")\n",
    "\n",
    "print(f\"\\nValidation Set Metrics:\")\n",
    "print(f\"  Silhouette Score: {validate_silhouette_hier:.4f}\")\n",
    "print(f\"  Davies-Bouldin Index: {validate_davies_bouldin_hier:.4f}\")\n",
    "\n",
    "print(f\"\\nTest Set Metrics:\")\n",
    "print(f\"  Silhouette Score: {test_silhouette_hier:.4f}\")\n",
    "print(f\"  Davies-Bouldin Index: {test_davies_bouldin_hier:.4f}\")\n",
    "\n",
    "print(f\"\\nCluster Distribution (Train):\")\n",
    "print(df_train['cluster_hierarchical'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "febae709",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize hierarchical clustering results\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "datasets_hier = [\n",
    "    (X_train_scaled, df_train['cluster_hierarchical'], 'Train'),\n",
    "    (X_validate_scaled, df_validate['cluster_hierarchical'], 'Validate'),\n",
    "    (X_test_scaled, df_test['cluster_hierarchical'], 'Test')\n",
    "]\n",
    "\n",
    "for ax, (X, clusters, title) in zip(axes, datasets_hier):\n",
    "    scatter = ax.scatter(X[:, 0], X[:, 1], c=clusters, cmap='viridis', alpha=0.6, s=30)\n",
    "    ax.scatter(hier_cluster_centers[:, 0], hier_cluster_centers[:, 1], \n",
    "               c='red', marker='X', s=200, edgecolors='black', linewidths=2, label='Centers')\n",
    "    ax.set_xlabel(f'Feature 1: {feature_cols[0]}')\n",
    "    ax.set_ylabel(f'Feature 2: {feature_cols[1]}')\n",
    "    ax.set_title(f'{title} Set - Hierarchical Clustering ({n_clusters_hier} clusters)')\n",
    "    ax.legend()\n",
    "    plt.colorbar(scatter, ax=ax, label='Cluster')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6105544c",
   "metadata": {},
   "source": [
    "### 7.2 Hierarchical Clustering on Z-Scored Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0cf127",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hierarchical clustering on z-scored data\n",
    "print(\"=== HIERARCHICAL CLUSTERING - Z-SCORED DATA (WARD LINKAGE) ===\\n\")\n",
    "\n",
    "# Compute linkage on z-scored training data\n",
    "linkage_train_z = linkage(X_train_z, method='ward')\n",
    "\n",
    "# Cut the dendrogram\n",
    "n_clusters_hier_z = optimal_k_z\n",
    "hierarchical_labels_train_z = fcluster(linkage_train_z, n_clusters_hier_z, criterion='maxclust')\n",
    "\n",
    "df_train_z['cluster_hierarchical'] = hierarchical_labels_train_z - 1\n",
    "\n",
    "# Compute cluster centers\n",
    "hier_cluster_centers_z = []\n",
    "for i in range(n_clusters_hier_z):\n",
    "    cluster_mask = df_train_z['cluster_hierarchical'] == i\n",
    "    center = X_train_z[cluster_mask].mean(axis=0)\n",
    "    hier_cluster_centers_z.append(center)\n",
    "hier_cluster_centers_z = np.array(hier_cluster_centers_z)\n",
    "\n",
    "# Assign validation and test data\n",
    "df_validate_z['cluster_hierarchical'] = cdist(X_validate_z, hier_cluster_centers_z).argmin(axis=1)\n",
    "df_test_z['cluster_hierarchical'] = cdist(X_test_z, hier_cluster_centers_z).argmin(axis=1)\n",
    "\n",
    "# Evaluate\n",
    "train_silhouette_hier_z = silhouette_score(X_train_z, df_train_z['cluster_hierarchical'])\n",
    "train_davies_bouldin_hier_z = davies_bouldin_score(X_train_z, df_train_z['cluster_hierarchical'])\n",
    "validate_silhouette_hier_z = silhouette_score(X_validate_z, df_validate_z['cluster_hierarchical'])\n",
    "validate_davies_bouldin_hier_z = davies_bouldin_score(X_validate_z, df_validate_z['cluster_hierarchical'])\n",
    "test_silhouette_hier_z = silhouette_score(X_test_z, df_test_z['cluster_hierarchical'])\n",
    "test_davies_bouldin_hier_z = davies_bouldin_score(X_test_z, df_test_z['cluster_hierarchical'])\n",
    "\n",
    "print(f\"Hierarchical Clustering with {n_clusters_hier_z} clusters (Ward Linkage, Z-Scored)\")\n",
    "print(f\"\\nTraining Set Metrics:\")\n",
    "print(f\"  Silhouette Score: {train_silhouette_hier_z:.4f}\")\n",
    "print(f\"  Davies-Bouldin Index: {train_davies_bouldin_hier_z:.4f}\")\n",
    "\n",
    "print(f\"\\nValidation Set Metrics:\")\n",
    "print(f\"  Silhouette Score: {validate_silhouette_hier_z:.4f}\")\n",
    "print(f\"  Davies-Bouldin Index: {validate_davies_bouldin_hier_z:.4f}\")\n",
    "\n",
    "print(f\"\\nTest Set Metrics:\")\n",
    "print(f\"  Silhouette Score: {test_silhouette_hier_z:.4f}\")\n",
    "print(f\"  Davies-Bouldin Index: {test_davies_bouldin_hier_z:.4f}\")\n",
    "\n",
    "print(f\"\\nCluster Distribution (Train):\")\n",
    "print(df_train_z['cluster_hierarchical'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645d049b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize z-scored hierarchical clustering results\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "datasets_hier_z = [\n",
    "    (X_train_z, df_train_z['cluster_hierarchical'], 'Train'),\n",
    "    (X_validate_z, df_validate_z['cluster_hierarchical'], 'Validate'),\n",
    "    (X_test_z, df_test_z['cluster_hierarchical'], 'Test')\n",
    "]\n",
    "\n",
    "for ax, (X, clusters, title) in zip(axes, datasets_hier_z):\n",
    "    scatter = ax.scatter(X[:, 0], X[:, 1], c=clusters, cmap='viridis', alpha=0.6, s=30)\n",
    "    ax.scatter(hier_cluster_centers_z[:, 0], hier_cluster_centers_z[:, 1], \n",
    "               c='red', marker='X', s=200, edgecolors='black', linewidths=2, label='Centers')\n",
    "    ax.set_xlabel(f'Feature 1: {feature_cols_z[0]}')\n",
    "    ax.set_ylabel(f'Feature 2: {feature_cols_z[1]}')\n",
    "    ax.set_title(f'{title} Set - Hierarchical Clustering ({n_clusters_hier_z} clusters, Z-Scored)')\n",
    "    ax.legend()\n",
    "    plt.colorbar(scatter, ax=ax, label='Cluster')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb1f596",
   "metadata": {},
   "source": [
    "---\n",
    "## 9. Density-Based Clustering (DBSCAN)\n",
    "\n",
    "DBSCAN (Density-Based Spatial Clustering of Applications with Noise) identifies clusters based on density and can detect outliers.\n",
    "\n",
    "**Key Advantages:**\n",
    "- Finds arbitrarily shaped clusters\n",
    "- Automatically identifies noise/outliers\n",
    "- Doesn't require pre-specifying number of clusters\n",
    "\n",
    "**Key Parameters:**\n",
    "- **eps**: Maximum distance between neighbors\n",
    "- **min_samples**: Minimum points to form a cluster\n",
    "\n",
    "### 9.1 DBSCAN on Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41e388a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# Determine optimal eps using k-distance graph\n",
    "print(\"=== FINDING OPTIMAL EPS FOR DBSCAN ===\\n\")\n",
    "\n",
    "# Use k=4 (2*dimensions) for k-nearest neighbors\n",
    "k = 4\n",
    "nbrs = NearestNeighbors(n_neighbors=k).fit(X_train_scaled)\n",
    "distances, indices = nbrs.kneighbors(X_train_scaled)\n",
    "\n",
    "# Sort distances\n",
    "distances = np.sort(distances[:, k-1], axis=0)\n",
    "\n",
    "# Plot k-distance graph\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(distances)\n",
    "plt.xlabel('Data Points sorted by distance')\n",
    "plt.ylabel(f'{k}-NN Distance')\n",
    "plt.title('K-Distance Graph for Epsilon Selection')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.axhline(y=np.percentile(distances, 95), color='r', linestyle='--', label='95th percentile')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Suggest eps based on elbow point (using 95th percentile as heuristic)\n",
    "suggested_eps = np.percentile(distances, 95)\n",
    "print(f\"Suggested eps (95th percentile): {suggested_eps:.4f}\")\n",
    "print(\"Look for the 'elbow' in the k-distance graph to choose eps\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b248944",
   "metadata": {},
   "source": [
    "### 8.1.1 DBSCAN Hyperparameter Tuning (Raw Data)\n",
    "\n",
    "DBSCAN has two key hyperparameters:\n",
    "- **eps**: Maximum distance between two points to be considered neighbors\n",
    "- **min_samples**: Minimum number of points to form a dense region (cluster)\n",
    "\n",
    "We'll test combinations to find optimal values based on:\n",
    "- **Silhouette Score**: Measures cluster quality (higher is better)\n",
    "- **Number of Clusters**: Should be meaningful (not 1, not too many)\n",
    "- **Noise Percentage**: Should be reasonable (<30%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ae519c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DBSCAN Hyperparameter Tuning - Raw Data\n",
    "print(\"=\"*80)\n",
    "print(\"DBSCAN HYPERPARAMETER TUNING - RAW DATA\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Define parameter grid\n",
    "eps_values = [0.01, 0.05, 0.1, 0.15, 0.2, 0.3, 0.5]\n",
    "min_samples_values = [3, 5, 7, 10]\n",
    "\n",
    "tuning_results = []\n",
    "\n",
    "print(\"\\nTesting combinations of eps and min_samples...\")\n",
    "print(\"(This may take a moment)\\n\")\n",
    "\n",
    "for eps in eps_values:\n",
    "    for min_samp in min_samples_values:\n",
    "        dbscan = DBSCAN(eps=eps, min_samples=min_samp)\n",
    "        labels = dbscan.fit_predict(X_train_scaled)\n",
    "        \n",
    "        n_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "        n_noise = list(labels).count(-1)\n",
    "        noise_pct = n_noise / len(labels) * 100\n",
    "        \n",
    "        # Calculate silhouette score if possible\n",
    "        if n_clusters > 1 and n_noise < len(labels) - 1:\n",
    "            mask = labels != -1\n",
    "            if mask.sum() > 1 and len(np.unique(labels[mask])) > 1:\n",
    "                sil_score = silhouette_score(X_train_scaled[mask], labels[mask])\n",
    "            else:\n",
    "                sil_score = -1\n",
    "        else:\n",
    "            sil_score = -1\n",
    "        \n",
    "        tuning_results.append({\n",
    "            'eps': eps,\n",
    "            'min_samples': min_samp,\n",
    "            'n_clusters': n_clusters,\n",
    "            'n_noise': n_noise,\n",
    "            'noise_pct': noise_pct,\n",
    "            'silhouette': sil_score\n",
    "        })\n",
    "\n",
    "# Convert to DataFrame\n",
    "tuning_df = pd.DataFrame(tuning_results)\n",
    "\n",
    "# Find best parameters based on different criteria\n",
    "print(\"=\"*80)\n",
    "print(\"TUNING RESULTS SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Filter valid results (at least 2 clusters, reasonable noise)\n",
    "valid_results = tuning_df[(tuning_df['n_clusters'] >= 2) & \n",
    "                          (tuning_df['noise_pct'] < 30) & \n",
    "                          (tuning_df['silhouette'] > 0)]\n",
    "\n",
    "if len(valid_results) > 0:\n",
    "    # Best by silhouette score\n",
    "    best_sil = valid_results.loc[valid_results['silhouette'].idxmax()]\n",
    "    print(f\"\\nBest by Silhouette Score:\")\n",
    "    print(f\"  eps={best_sil['eps']:.2f}, min_samples={int(best_sil['min_samples'])}\")\n",
    "    print(f\"  Clusters: {int(best_sil['n_clusters'])}, Noise: {best_sil['noise_pct']:.1f}%, Silhouette: {best_sil['silhouette']:.4f}\")\n",
    "    \n",
    "    # Best by balanced noise and silhouette\n",
    "    valid_results['score'] = valid_results['silhouette'] * (1 - valid_results['noise_pct']/100)\n",
    "    best_balanced = valid_results.loc[valid_results['score'].idxmax()]\n",
    "    print(f\"\\nBest Balanced (Silhouette Ã— Low Noise):\")\n",
    "    print(f\"  eps={best_balanced['eps']:.2f}, min_samples={int(best_balanced['min_samples'])}\")\n",
    "    print(f\"  Clusters: {int(best_balanced['n_clusters'])}, Noise: {best_balanced['noise_pct']:.1f}%, Silhouette: {best_balanced['silhouette']:.4f}\")\n",
    "else:\n",
    "    print(\"\\nâš ï¸  No valid parameter combinations found!\")\n",
    "    print(\"Try expanding the search range.\")\n",
    "\n",
    "# Show top 10 results\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"TOP 10 PARAMETER COMBINATIONS (by Silhouette Score):\")\n",
    "print(f\"{'='*80}\")\n",
    "top_results = tuning_df[tuning_df['silhouette'] > 0].nlargest(10, 'silhouette')\n",
    "print(top_results.to_string(index=False))\n",
    "\n",
    "# Create heatmap of results\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"SILHOUETTE SCORE HEATMAP:\")\n",
    "print(\"(Higher is better; -1 indicates invalid configuration)\")\n",
    "print(f\"{'='*80}\\n\")\n",
    "\n",
    "# Pivot table for heatmap\n",
    "pivot_sil = tuning_df.pivot_table(values='silhouette', index='min_samples', columns='eps')\n",
    "print(pivot_sil.to_string())\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"NUMBER OF CLUSTERS HEATMAP:\")\n",
    "print(f\"{'='*80}\\n\")\n",
    "pivot_clusters = tuning_df.pivot_table(values='n_clusters', index='min_samples', columns='eps')\n",
    "print(pivot_clusters.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543fc9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize DBSCAN hyperparameter tuning results - Raw Data\n",
    "fig, axes = plt.subplots(1, 3, figsize=(20, 5))\n",
    "\n",
    "# Silhouette Score Heatmap\n",
    "pivot_sil = tuning_df.pivot_table(values='silhouette', index='min_samples', columns='eps')\n",
    "im1 = axes[0].imshow(pivot_sil, cmap='RdYlGn', aspect='auto', vmin=-1, vmax=1)\n",
    "axes[0].set_xticks(range(len(pivot_sil.columns)))\n",
    "axes[0].set_xticklabels([f'{x:.2f}' for x in pivot_sil.columns], rotation=45)\n",
    "axes[0].set_yticks(range(len(pivot_sil.index)))\n",
    "axes[0].set_yticklabels(pivot_sil.index)\n",
    "axes[0].set_xlabel('eps')\n",
    "axes[0].set_ylabel('min_samples')\n",
    "axes[0].set_title('Silhouette Score (Higher = Better)')\n",
    "plt.colorbar(im1, ax=axes[0])\n",
    "\n",
    "# Add text annotations\n",
    "for i in range(len(pivot_sil.index)):\n",
    "    for j in range(len(pivot_sil.columns)):\n",
    "        val = pivot_sil.iloc[i, j]\n",
    "        text_color = 'white' if val < 0 else 'black'\n",
    "        axes[0].text(j, i, f'{val:.2f}', ha='center', va='center', color=text_color, fontsize=8)\n",
    "\n",
    "# Number of Clusters Heatmap\n",
    "pivot_clusters = tuning_df.pivot_table(values='n_clusters', index='min_samples', columns='eps')\n",
    "im2 = axes[1].imshow(pivot_clusters, cmap='viridis', aspect='auto')\n",
    "axes[1].set_xticks(range(len(pivot_clusters.columns)))\n",
    "axes[1].set_xticklabels([f'{x:.2f}' for x in pivot_clusters.columns], rotation=45)\n",
    "axes[1].set_yticks(range(len(pivot_clusters.index)))\n",
    "axes[1].set_yticklabels(pivot_clusters.index)\n",
    "axes[1].set_xlabel('eps')\n",
    "axes[1].set_ylabel('min_samples')\n",
    "axes[1].set_title('Number of Clusters')\n",
    "plt.colorbar(im2, ax=axes[1])\n",
    "\n",
    "# Add text annotations\n",
    "for i in range(len(pivot_clusters.index)):\n",
    "    for j in range(len(pivot_clusters.columns)):\n",
    "        val = pivot_clusters.iloc[i, j]\n",
    "        axes[1].text(j, i, f'{int(val)}', ha='center', va='center', color='white', fontsize=8)\n",
    "\n",
    "# Noise Percentage Heatmap\n",
    "pivot_noise = tuning_df.pivot_table(values='noise_pct', index='min_samples', columns='eps')\n",
    "im3 = axes[2].imshow(pivot_noise, cmap='RdYlGn_r', aspect='auto', vmin=0, vmax=100)\n",
    "axes[2].set_xticks(range(len(pivot_noise.columns)))\n",
    "axes[2].set_xticklabels([f'{x:.2f}' for x in pivot_noise.columns], rotation=45)\n",
    "axes[2].set_yticks(range(len(pivot_noise.index)))\n",
    "axes[2].set_yticklabels(pivot_noise.index)\n",
    "axes[2].set_xlabel('eps')\n",
    "axes[2].set_ylabel('min_samples')\n",
    "axes[2].set_title('Noise % (Lower = Better)')\n",
    "plt.colorbar(im3, ax=axes[2])\n",
    "\n",
    "# Add text annotations\n",
    "for i in range(len(pivot_noise.index)):\n",
    "    for j in range(len(pivot_noise.columns)):\n",
    "        val = pivot_noise.iloc[i, j]\n",
    "        text_color = 'white' if val > 50 else 'black'\n",
    "        axes[2].text(j, i, f'{val:.0f}%', ha='center', va='center', color=text_color, fontsize=8)\n",
    "\n",
    "plt.suptitle('DBSCAN Hyperparameter Tuning - Raw Data', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3998fc54",
   "metadata": {},
   "source": [
    "### 8.1.2 Apply DBSCAN with Best Parameters (Raw Data)\n",
    "\n",
    "Based on the tuning results above, update the `chosen_eps` and `chosen_min_samples` values in the next cell.\n",
    "\n",
    "**Selection Guidelines:**\n",
    "- âœ… Choose parameters with **high Silhouette Score** (>0.3)\n",
    "- âœ… Ensure **multiple clusters** are found (not just 1)\n",
    "- âœ… Keep **noise percentage reasonable** (<20-30%)\n",
    "- âš ï¸ Balance between cluster quality and noise tolerance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1337d155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auto-select best DBSCAN parameters from tuning results (Raw Data)\n",
    "if len(valid_results) > 0:\n",
    "    # Use the balanced best (silhouette Ã— low noise)\n",
    "    auto_eps = best_balanced['eps']\n",
    "    auto_min_samples = int(best_balanced['min_samples'])\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(\"RECOMMENDED PARAMETERS (Auto-Selected):\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"\\nchosen_eps = {auto_eps}\")\n",
    "    print(f\"chosen_min_samples = {auto_min_samples}\")\n",
    "    print(f\"\\nExpected Results:\")\n",
    "    print(f\"  - Clusters: {int(best_balanced['n_clusters'])}\")\n",
    "    print(f\"  - Noise: {best_balanced['noise_pct']:.1f}%\")\n",
    "    print(f\"  - Silhouette: {best_balanced['silhouette']:.4f}\")\n",
    "    print(\"\\nCopy these values to the next cell or adjust as needed.\")\n",
    "    print(\"=\"*80)\n",
    "else:\n",
    "    print(\"âš ï¸ No valid parameters found in tuning. Check the heatmaps and select manually.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac069bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply DBSCAN with tuned parameters - Raw Data\n",
    "# IMPORTANT: Update these values based on the hyperparameter tuning results above\n",
    "# Look for the \"Best by Silhouette Score\" or \"Best Balanced\" recommendation\n",
    "\n",
    "chosen_eps = 0.1  # Update based on tuning results\n",
    "chosen_min_samples = 5  # Update based on tuning results\n",
    "\n",
    "print(f\"\\n=== DBSCAN CLUSTERING - RAW DATA (eps={chosen_eps}, min_samples={chosen_min_samples}) ===\\n\")\n",
    "\n",
    "# Fit DBSCAN on training data\n",
    "dbscan = DBSCAN(eps=chosen_eps, min_samples=chosen_min_samples)\n",
    "dbscan_labels_train = dbscan.fit_predict(X_train_scaled)\n",
    "\n",
    "df_train['cluster_dbscan'] = dbscan_labels_train\n",
    "\n",
    "# For validation and test sets, assign to nearest cluster (excluding noise)\n",
    "# Get cluster centers (excluding noise points labeled as -1)\n",
    "dbscan_cluster_centers = []\n",
    "unique_labels = set(dbscan_labels_train)\n",
    "if -1 in unique_labels:\n",
    "    unique_labels.remove(-1)\n",
    "\n",
    "for label in sorted(unique_labels):\n",
    "    cluster_mask = dbscan_labels_train == label\n",
    "    center = X_train_scaled[cluster_mask].mean(axis=0)\n",
    "    dbscan_cluster_centers.append(center)\n",
    "\n",
    "if len(dbscan_cluster_centers) > 0:\n",
    "    dbscan_cluster_centers = np.array(dbscan_cluster_centers)\n",
    "    \n",
    "    # Assign validation and test data to nearest cluster\n",
    "    df_validate['cluster_dbscan'] = cdist(X_validate_scaled, dbscan_cluster_centers).argmin(axis=1)\n",
    "    df_test['cluster_dbscan'] = cdist(X_test_scaled, dbscan_cluster_centers).argmin(axis=1)\n",
    "    \n",
    "    # Evaluate (excluding noise points from training)\n",
    "    train_mask = dbscan_labels_train != -1\n",
    "    # Check for at least 2 non-noise points AND at least 2 unique clusters\n",
    "    if train_mask.sum() > 1 and len(np.unique(dbscan_labels_train[train_mask])) > 1:\n",
    "        train_silhouette_dbscan = silhouette_score(X_train_scaled[train_mask], dbscan_labels_train[train_mask])\n",
    "        train_davies_bouldin_dbscan = davies_bouldin_score(X_train_scaled[train_mask], dbscan_labels_train[train_mask])\n",
    "    else:\n",
    "        train_silhouette_dbscan = -1\n",
    "        train_davies_bouldin_dbscan = -1\n",
    "    \n",
    "    # Check if validate/test have at least 2 unique clusters (happens when training found only 1 cluster)\n",
    "    if len(np.unique(df_validate['cluster_dbscan'])) > 1:\n",
    "        validate_silhouette_dbscan = silhouette_score(X_validate_scaled, df_validate['cluster_dbscan'])\n",
    "        validate_davies_bouldin_dbscan = davies_bouldin_score(X_validate_scaled, df_validate['cluster_dbscan'])\n",
    "    else:\n",
    "        validate_silhouette_dbscan = -1\n",
    "        validate_davies_bouldin_dbscan = -1\n",
    "    \n",
    "    if len(np.unique(df_test['cluster_dbscan'])) > 1:\n",
    "        test_silhouette_dbscan = silhouette_score(X_test_scaled, df_test['cluster_dbscan'])\n",
    "        test_davies_bouldin_dbscan = davies_bouldin_score(X_test_scaled, df_test['cluster_dbscan'])\n",
    "    else:\n",
    "        test_silhouette_dbscan = -1\n",
    "        test_davies_bouldin_dbscan = -1\n",
    "    \n",
    "    n_clusters_found = len(unique_labels)\n",
    "    n_noise = list(dbscan_labels_train).count(-1)\n",
    "    \n",
    "    print(f\"DBSCAN Results:\")\n",
    "    print(f\"  Clusters found: {n_clusters_found}\")\n",
    "    print(f\"  Noise points: {n_noise} ({n_noise/len(dbscan_labels_train)*100:.1f}%)\")\n",
    "    \n",
    "    print(f\"\\nTraining Set Metrics (excluding noise):\")\n",
    "    print(f\"  Silhouette Score: {f'{train_silhouette_dbscan:.4f}' if train_silhouette_dbscan > 0 else 'N/A'}\")\n",
    "    print(f\"  Davies-Bouldin Index: {f'{train_davies_bouldin_dbscan:.4f}' if train_davies_bouldin_dbscan > 0 else 'N/A'}\")\n",
    "    \n",
    "    print(f\"\\nValidation Set Metrics:\")\n",
    "    print(f\"  Silhouette Score: {f'{validate_silhouette_dbscan:.4f}' if validate_silhouette_dbscan > 0 else 'N/A'}\")\n",
    "    print(f\"  Davies-Bouldin Index: {f'{validate_davies_bouldin_dbscan:.4f}' if validate_davies_bouldin_dbscan > 0 else 'N/A'}\")\n",
    "    \n",
    "    print(f\"\\nTest Set Metrics:\")\n",
    "    print(f\"  Silhouette Score: {f'{test_silhouette_dbscan:.4f}' if test_silhouette_dbscan > 0 else 'N/A'}\")\n",
    "    print(f\"  Davies-Bouldin Index: {f'{test_davies_bouldin_dbscan:.4f}' if test_davies_bouldin_dbscan > 0 else 'N/A'}\")\n",
    "    \n",
    "    print(f\"\\nCluster Distribution (Train, including noise as -1):\")\n",
    "    print(df_train['cluster_dbscan'].value_counts().sort_index())\n",
    "else:\n",
    "    print(\"No clusters found - all points classified as noise!\")\n",
    "    print(\"âš ï¸ Try increasing eps or decreasing min_samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7260a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize DBSCAN results\n",
    "if len(dbscan_cluster_centers) > 0:\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "    \n",
    "    datasets_dbscan = [\n",
    "        (X_train_scaled, df_train['cluster_dbscan'], 'Train'),\n",
    "        (X_validate_scaled, df_validate['cluster_dbscan'], 'Validate'),\n",
    "        (X_test_scaled, df_test['cluster_dbscan'], 'Test')\n",
    "    ]\n",
    "    \n",
    "    for ax, (X, clusters, title) in zip(axes, datasets_dbscan):\n",
    "        # Use different color for noise points (-1)\n",
    "        scatter = ax.scatter(X[:, 0], X[:, 1], c=clusters, cmap='viridis', alpha=0.6, s=30)\n",
    "        if len(dbscan_cluster_centers) > 0:\n",
    "            ax.scatter(dbscan_cluster_centers[:, 0], dbscan_cluster_centers[:, 1], \n",
    "                       c='red', marker='X', s=200, edgecolors='black', linewidths=2, label='Centers')\n",
    "        ax.set_xlabel(f'Feature 1: {feature_cols[0]}')\n",
    "        ax.set_ylabel(f'Feature 2: {feature_cols[1]}')\n",
    "        ax.set_title(f'{title} Set - DBSCAN (eps={chosen_eps}, noise=-1)')\n",
    "        ax.legend()\n",
    "        plt.colorbar(scatter, ax=ax, label='Cluster')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Cannot visualize - no clusters found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b47bdd3",
   "metadata": {},
   "source": [
    "---\n",
    "## 9.2 DBSCAN on Z-Scored Data\n",
    "\n",
    "### 9.2.1 DBSCAN Hyperparameter Tuning (Z-Scored Data)\n",
    "\n",
    "For z-scored data (normalized with mean=0, std=1), we need **smaller eps values** than raw data because distances are compressed. We'll test appropriate ranges for this normalized space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e846d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find optimal eps for z-scored data\n",
    "print(\"=== FINDING OPTIMAL EPS FOR DBSCAN (Z-SCORED DATA) ===\\n\")\n",
    "\n",
    "k = 4\n",
    "nbrs_z = NearestNeighbors(n_neighbors=k).fit(X_train_z)\n",
    "distances_z, indices_z = nbrs_z.kneighbors(X_train_z)\n",
    "distances_z = np.sort(distances_z[:, k-1], axis=0)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(distances_z)\n",
    "plt.xlabel('Data Points sorted by distance')\n",
    "plt.ylabel(f'{k}-NN Distance')\n",
    "plt.title('K-Distance Graph for Epsilon Selection (Z-Scored Data)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.axhline(y=np.percentile(distances_z, 95), color='r', linestyle='--', label='95th percentile')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "suggested_eps_z = np.percentile(distances_z, 95)\n",
    "print(f\"Suggested eps (95th percentile): {suggested_eps_z:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c9308b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DBSCAN Hyperparameter Tuning - Z-Scored Data\n",
    "print(\"=\"*80)\n",
    "print(\"DBSCAN HYPERPARAMETER TUNING - Z-SCORED DATA\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# For z-scored data, use SMALLER eps values (data is normalized)\n",
    "eps_values_z = [0.05, 0.1, 0.15, 0.2, 0.3, 0.5, 0.7, 1.0]\n",
    "min_samples_values_z = [3, 5, 7, 10]\n",
    "\n",
    "tuning_results_z = []\n",
    "\n",
    "print(\"\\nTesting combinations of eps and min_samples...\")\n",
    "print(\"(This may take a moment)\\n\")\n",
    "\n",
    "for eps in eps_values_z:\n",
    "    for min_samp in min_samples_values_z:\n",
    "        dbscan_z = DBSCAN(eps=eps, min_samples=min_samp)\n",
    "        labels_z = dbscan_z.fit_predict(X_train_z)\n",
    "        \n",
    "        n_clusters = len(set(labels_z)) - (1 if -1 in labels_z else 0)\n",
    "        n_noise = list(labels_z).count(-1)\n",
    "        noise_pct = n_noise / len(labels_z) * 100\n",
    "        \n",
    "        # Calculate silhouette score if possible\n",
    "        if n_clusters > 1 and n_noise < len(labels_z) - 1:\n",
    "            mask = labels_z != -1\n",
    "            if mask.sum() > 1 and len(np.unique(labels_z[mask])) > 1:\n",
    "                sil_score = silhouette_score(X_train_z[mask], labels_z[mask])\n",
    "            else:\n",
    "                sil_score = -1\n",
    "        else:\n",
    "            sil_score = -1\n",
    "        \n",
    "        tuning_results_z.append({\n",
    "            'eps': eps,\n",
    "            'min_samples': min_samp,\n",
    "            'n_clusters': n_clusters,\n",
    "            'n_noise': n_noise,\n",
    "            'noise_pct': noise_pct,\n",
    "            'silhouette': sil_score\n",
    "        })\n",
    "\n",
    "# Convert to DataFrame\n",
    "tuning_df_z = pd.DataFrame(tuning_results_z)\n",
    "\n",
    "# Find best parameters based on different criteria\n",
    "print(\"=\"*80)\n",
    "print(\"TUNING RESULTS SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Filter valid results (at least 2 clusters, reasonable noise)\n",
    "valid_results_z = tuning_df_z[(tuning_df_z['n_clusters'] >= 2) & \n",
    "                              (tuning_df_z['noise_pct'] < 30) & \n",
    "                              (tuning_df_z['silhouette'] > 0)]\n",
    "\n",
    "if len(valid_results_z) > 0:\n",
    "    # Best by silhouette score\n",
    "    best_sil_z = valid_results_z.loc[valid_results_z['silhouette'].idxmax()]\n",
    "    print(f\"\\nBest by Silhouette Score:\")\n",
    "    print(f\"  eps={best_sil_z['eps']:.2f}, min_samples={int(best_sil_z['min_samples'])}\")\n",
    "    print(f\"  Clusters: {int(best_sil_z['n_clusters'])}, Noise: {best_sil_z['noise_pct']:.1f}%, Silhouette: {best_sil_z['silhouette']:.4f}\")\n",
    "    \n",
    "    # Best by balanced noise and silhouette\n",
    "    valid_results_z['score'] = valid_results_z['silhouette'] * (1 - valid_results_z['noise_pct']/100)\n",
    "    best_balanced_z = valid_results_z.loc[valid_results_z['score'].idxmax()]\n",
    "    print(f\"\\nBest Balanced (Silhouette Ã— Low Noise):\")\n",
    "    print(f\"  eps={best_balanced_z['eps']:.2f}, min_samples={int(best_balanced_z['min_samples'])}\")\n",
    "    print(f\"  Clusters: {int(best_balanced_z['n_clusters'])}, Noise: {best_balanced_z['noise_pct']:.1f}%, Silhouette: {best_balanced_z['silhouette']:.4f}\")\n",
    "else:\n",
    "    print(\"\\nâš ï¸  No valid parameter combinations found!\")\n",
    "    print(\"Try expanding the search range.\")\n",
    "\n",
    "# Show top 10 results\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"TOP 10 PARAMETER COMBINATIONS (by Silhouette Score):\")\n",
    "print(f\"{'='*80}\")\n",
    "top_results_z = tuning_df_z[tuning_df_z['silhouette'] > 0].nlargest(10, 'silhouette')\n",
    "print(top_results_z.to_string(index=False))\n",
    "\n",
    "# Create heatmap of results\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"SILHOUETTE SCORE HEATMAP:\")\n",
    "print(\"(Higher is better; -1 indicates invalid configuration)\")\n",
    "print(f\"{'='*80}\\n\")\n",
    "\n",
    "# Pivot table for heatmap\n",
    "pivot_sil_z = tuning_df_z.pivot_table(values='silhouette', index='min_samples', columns='eps')\n",
    "print(pivot_sil_z.to_string())\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"NUMBER OF CLUSTERS HEATMAP:\")\n",
    "print(f\"{'='*80}\\n\")\n",
    "pivot_clusters_z = tuning_df_z.pivot_table(values='n_clusters', index='min_samples', columns='eps')\n",
    "print(pivot_clusters_z.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d42d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize DBSCAN hyperparameter tuning results - Z-Scored Data\n",
    "fig, axes = plt.subplots(1, 3, figsize=(20, 5))\n",
    "\n",
    "# Silhouette Score Heatmap\n",
    "pivot_sil_z = tuning_df_z.pivot_table(values='silhouette', index='min_samples', columns='eps')\n",
    "im1 = axes[0].imshow(pivot_sil_z, cmap='RdYlGn', aspect='auto', vmin=-1, vmax=1)\n",
    "axes[0].set_xticks(range(len(pivot_sil_z.columns)))\n",
    "axes[0].set_xticklabels([f'{x:.2f}' for x in pivot_sil_z.columns], rotation=45)\n",
    "axes[0].set_yticks(range(len(pivot_sil_z.index)))\n",
    "axes[0].set_yticklabels(pivot_sil_z.index)\n",
    "axes[0].set_xlabel('eps')\n",
    "axes[0].set_ylabel('min_samples')\n",
    "axes[0].set_title('Silhouette Score (Higher = Better)')\n",
    "plt.colorbar(im1, ax=axes[0])\n",
    "\n",
    "# Add text annotations\n",
    "for i in range(len(pivot_sil_z.index)):\n",
    "    for j in range(len(pivot_sil_z.columns)):\n",
    "        val = pivot_sil_z.iloc[i, j]\n",
    "        text_color = 'white' if val < 0 else 'black'\n",
    "        axes[0].text(j, i, f'{val:.2f}', ha='center', va='center', color=text_color, fontsize=8)\n",
    "\n",
    "# Number of Clusters Heatmap\n",
    "pivot_clusters_z = tuning_df_z.pivot_table(values='n_clusters', index='min_samples', columns='eps')\n",
    "im2 = axes[1].imshow(pivot_clusters_z, cmap='viridis', aspect='auto')\n",
    "axes[1].set_xticks(range(len(pivot_clusters_z.columns)))\n",
    "axes[1].set_xticklabels([f'{x:.2f}' for x in pivot_clusters_z.columns], rotation=45)\n",
    "axes[1].set_yticks(range(len(pivot_clusters_z.index)))\n",
    "axes[1].set_yticklabels(pivot_clusters_z.index)\n",
    "axes[1].set_xlabel('eps')\n",
    "axes[1].set_ylabel('min_samples')\n",
    "axes[1].set_title('Number of Clusters')\n",
    "plt.colorbar(im2, ax=axes[1])\n",
    "\n",
    "# Add text annotations\n",
    "for i in range(len(pivot_clusters_z.index)):\n",
    "    for j in range(len(pivot_clusters_z.columns)):\n",
    "        val = pivot_clusters_z.iloc[i, j]\n",
    "        axes[1].text(j, i, f'{int(val)}', ha='center', va='center', color='white', fontsize=8)\n",
    "\n",
    "# Noise Percentage Heatmap\n",
    "pivot_noise_z = tuning_df_z.pivot_table(values='noise_pct', index='min_samples', columns='eps')\n",
    "im3 = axes[2].imshow(pivot_noise_z, cmap='RdYlGn_r', aspect='auto', vmin=0, vmax=100)\n",
    "axes[2].set_xticks(range(len(pivot_noise_z.columns)))\n",
    "axes[2].set_xticklabels([f'{x:.2f}' for x in pivot_noise_z.columns], rotation=45)\n",
    "axes[2].set_yticks(range(len(pivot_noise_z.index)))\n",
    "axes[2].set_yticklabels(pivot_noise_z.index)\n",
    "axes[2].set_xlabel('eps')\n",
    "axes[2].set_ylabel('min_samples')\n",
    "axes[2].set_title('Noise % (Lower = Better)')\n",
    "plt.colorbar(im3, ax=axes[2])\n",
    "\n",
    "# Add text annotations\n",
    "for i in range(len(pivot_noise_z.index)):\n",
    "    for j in range(len(pivot_noise_z.columns)):\n",
    "        val = pivot_noise_z.iloc[i, j]\n",
    "        text_color = 'white' if val > 50 else 'black'\n",
    "        axes[2].text(j, i, f'{val:.0f}%', ha='center', va='center', color=text_color, fontsize=8)\n",
    "\n",
    "plt.suptitle('DBSCAN Hyperparameter Tuning - Z-Scored Data', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ecf4d4b",
   "metadata": {},
   "source": [
    "### 8.2.2 Apply DBSCAN with Best Parameters (Z-Scored Data)\n",
    "\n",
    "Based on the tuning results above, update the `chosen_eps_z` and `chosen_min_samples_z` values in the next cell.\n",
    "\n",
    "**Remember:** Z-scored data requires **smaller eps values** (typically 0.05-0.3) than raw data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770b6867",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auto-select best DBSCAN parameters from tuning results (Z-Scored Data)\n",
    "if len(valid_results_z) > 0:\n",
    "    # Use the balanced best (silhouette Ã— low noise)\n",
    "    auto_eps_z = best_balanced_z['eps']\n",
    "    auto_min_samples_z = int(best_balanced_z['min_samples'])\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(\"RECOMMENDED PARAMETERS (Auto-Selected):\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"\\nchosen_eps_z = {auto_eps_z}\")\n",
    "    print(f\"chosen_min_samples_z = {auto_min_samples_z}\")\n",
    "    print(f\"\\nExpected Results:\")\n",
    "    print(f\"  - Clusters: {int(best_balanced_z['n_clusters'])}\")\n",
    "    print(f\"  - Noise: {best_balanced_z['noise_pct']:.1f}%\")\n",
    "    print(f\"  - Silhouette: {best_balanced_z['silhouette']:.4f}\")\n",
    "    print(\"\\nCopy these values to the next cell or adjust as needed.\")\n",
    "    print(\"=\"*80)\n",
    "else:\n",
    "    print(\"âš ï¸ No valid parameters found in tuning. Check the heatmaps and select manually.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d87ef00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply DBSCAN with tuned parameters - Z-Scored Data\n",
    "# IMPORTANT: Update these values based on the hyperparameter tuning results above\n",
    "# Look for the \"Best by Silhouette Score\" or \"Best Balanced\" recommendation\n",
    "# NOTE: For z-scored data, use SMALLER eps values than raw data\n",
    "\n",
    "chosen_eps_z = 0.5  # Update based on tuning results (typically 0.05-0.3 for z-scored)\n",
    "chosen_min_samples_z = 3  # Update based on tuning results\n",
    "\n",
    "print(f\"\\n=== DBSCAN CLUSTERING - Z-SCORED (eps={chosen_eps_z}, min_samples={chosen_min_samples_z}) ===\\n\")\n",
    "\n",
    "dbscan_z = DBSCAN(eps=chosen_eps_z, min_samples=chosen_min_samples_z)\n",
    "dbscan_labels_train_z = dbscan_z.fit_predict(X_train_z)\n",
    "\n",
    "df_train_z['cluster_dbscan'] = dbscan_labels_train_z\n",
    "\n",
    "# Get cluster centers (excluding noise)\n",
    "dbscan_cluster_centers_z = []\n",
    "unique_labels_z = set(dbscan_labels_train_z)\n",
    "if -1 in unique_labels_z:\n",
    "    unique_labels_z.remove(-1)\n",
    "\n",
    "for label in sorted(unique_labels_z):\n",
    "    cluster_mask = dbscan_labels_train_z == label\n",
    "    center = X_train_z[cluster_mask].mean(axis=0)\n",
    "    dbscan_cluster_centers_z.append(center)\n",
    "\n",
    "if len(dbscan_cluster_centers_z) > 0:\n",
    "    dbscan_cluster_centers_z = np.array(dbscan_cluster_centers_z)\n",
    "    \n",
    "    df_validate_z['cluster_dbscan'] = cdist(X_validate_z, dbscan_cluster_centers_z).argmin(axis=1)\n",
    "    df_test_z['cluster_dbscan'] = cdist(X_test_z, dbscan_cluster_centers_z).argmin(axis=1)\n",
    "    \n",
    "    train_mask_z = dbscan_labels_train_z != -1\n",
    "    # Check for at least 2 non-noise points AND at least 2 unique clusters\n",
    "    if train_mask_z.sum() > 1 and len(np.unique(dbscan_labels_train_z[train_mask_z])) > 1:\n",
    "        train_silhouette_dbscan_z = silhouette_score(X_train_z[train_mask_z], dbscan_labels_train_z[train_mask_z])\n",
    "        train_davies_bouldin_dbscan_z = davies_bouldin_score(X_train_z[train_mask_z], dbscan_labels_train_z[train_mask_z])\n",
    "    else:\n",
    "        train_silhouette_dbscan_z = -1\n",
    "        train_davies_bouldin_dbscan_z = -1\n",
    "    \n",
    "    # Check if validate/test have at least 2 unique clusters (happens when training found only 1 cluster)\n",
    "    if len(np.unique(df_validate_z['cluster_dbscan'])) > 1:\n",
    "        validate_silhouette_dbscan_z = silhouette_score(X_validate_z, df_validate_z['cluster_dbscan'])\n",
    "        validate_davies_bouldin_dbscan_z = davies_bouldin_score(X_validate_z, df_validate_z['cluster_dbscan'])\n",
    "    else:\n",
    "        validate_silhouette_dbscan_z = -1\n",
    "        validate_davies_bouldin_dbscan_z = -1\n",
    "    \n",
    "    if len(np.unique(df_test_z['cluster_dbscan'])) > 1:\n",
    "        test_silhouette_dbscan_z = silhouette_score(X_test_z, df_test_z['cluster_dbscan'])\n",
    "        test_davies_bouldin_dbscan_z = davies_bouldin_score(X_test_z, df_test_z['cluster_dbscan'])\n",
    "    else:\n",
    "        test_silhouette_dbscan_z = -1\n",
    "        test_davies_bouldin_dbscan_z = -1\n",
    "    \n",
    "    n_clusters_found_z = len(unique_labels_z)\n",
    "    n_noise_z = list(dbscan_labels_train_z).count(-1)\n",
    "    \n",
    "    print(f\"DBSCAN Results (Z-Scored):\")\n",
    "    print(f\"  Clusters found: {n_clusters_found_z}\")\n",
    "    print(f\"  Noise points: {n_noise_z} ({n_noise_z/len(dbscan_labels_train_z)*100:.1f}%)\")\n",
    "    \n",
    "    print(f\"\\nTraining Set Metrics (excluding noise):\")\n",
    "    print(f\"  Silhouette Score: {f'{train_silhouette_dbscan_z:.4f}' if train_silhouette_dbscan_z > 0 else 'N/A'}\")\n",
    "    print(f\"  Davies-Bouldin Index: {f'{train_davies_bouldin_dbscan_z:.4f}' if train_davies_bouldin_dbscan_z > 0 else 'N/A'}\")\n",
    "    \n",
    "    print(f\"\\nValidation Set Metrics:\")\n",
    "    print(f\"  Silhouette Score: {f'{validate_silhouette_dbscan_z:.4f}' if validate_silhouette_dbscan_z > 0 else 'N/A'}\")\n",
    "    print(f\"  Davies-Bouldin Index: {f'{validate_davies_bouldin_dbscan_z:.4f}' if validate_davies_bouldin_dbscan_z > 0 else 'N/A'}\")\n",
    "    \n",
    "    print(f\"\\nTest Set Metrics:\")\n",
    "    print(f\"  Silhouette Score: {f'{test_silhouette_dbscan_z:.4f}' if test_silhouette_dbscan_z > 0 else 'N/A'}\")\n",
    "    print(f\"  Davies-Bouldin Index: {f'{test_davies_bouldin_dbscan_z:.4f}' if test_davies_bouldin_dbscan_z > 0 else 'N/A'}\")\n",
    "    \n",
    "    print(f\"\\nCluster Distribution (Train, including noise as -1):\")\n",
    "    print(df_train_z['cluster_dbscan'].value_counts().sort_index())\n",
    "else:\n",
    "    print(\"No clusters found - all points classified as noise!\")\n",
    "    print(\"âš ï¸ Try increasing eps or decreasing min_samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05046dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diagnostic: Check DBSCAN z-scored results\n",
    "print(\"\\n=== DBSCAN Z-SCORED DIAGNOSTIC ===\\n\")\n",
    "print(f\"Number of clusters found: {n_clusters_found_z}\")\n",
    "print(f\"Number of noise points: {n_noise_z}\")\n",
    "print(f\"Unique cluster labels: {sorted(unique_labels_z)}\")\n",
    "print(f\"\\nNumber of unique clusters (non-noise): {len(np.unique(dbscan_labels_train_z[dbscan_labels_train_z != -1]))}\")\n",
    "\n",
    "print(\"\\n--- RECOMMENDATION ---\")\n",
    "if n_clusters_found_z == 1:\n",
    "    print(\"âš ï¸  DBSCAN found only 1 cluster with eps=0.5\")\n",
    "    print(\"This is because eps=0.5 is too LARGE for z-scored data.\")\n",
    "    print(\"In z-scored space, data is normalized (mean=0, std=1).\")\n",
    "    print(\"Try SMALLER epsilon values: 0.05, 0.1, 0.15, 0.2, 0.3\")\n",
    "    print(\"\\nBased on the eps testing above, choose an eps value that gives:\")\n",
    "    print(\"  - Multiple clusters (not just 1)\")\n",
    "    print(\"  - Reasonable silhouette score\")\n",
    "    print(\"  - Acceptable noise percentage (<20%)\")\n",
    "else:\n",
    "    print(f\"âœ“ DBSCAN found {n_clusters_found_z} clusters\")\n",
    "    print(\"Continue with analysis!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05d6f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize DBSCAN results (z-scored)\n",
    "if len(dbscan_cluster_centers_z) > 0:\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "    \n",
    "    datasets_dbscan_z = [\n",
    "        (X_train_z, df_train_z['cluster_dbscan'], 'Train'),\n",
    "        (X_validate_z, df_validate_z['cluster_dbscan'], 'Validate'),\n",
    "        (X_test_z, df_test_z['cluster_dbscan'], 'Test')\n",
    "    ]\n",
    "    \n",
    "    for ax, (X, clusters, title) in zip(axes, datasets_dbscan_z):\n",
    "        scatter = ax.scatter(X[:, 0], X[:, 1], c=clusters, cmap='viridis', alpha=0.6, s=30)\n",
    "        if len(dbscan_cluster_centers_z) > 0:\n",
    "            ax.scatter(dbscan_cluster_centers_z[:, 0], dbscan_cluster_centers_z[:, 1], \n",
    "                       c='red', marker='X', s=200, edgecolors='black', linewidths=2, label='Centers')\n",
    "        ax.set_xlabel(f'Feature 1: {feature_cols_z[0]}')\n",
    "        ax.set_ylabel(f'Feature 2: {feature_cols_z[1]}')\n",
    "        ax.set_title(f'{title} Set - DBSCAN Z-Scored (eps={chosen_eps_z}, noise=-1)')\n",
    "        ax.legend()\n",
    "        plt.colorbar(scatter, ax=ax, label='Cluster')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Cannot visualize - no clusters found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb88b55",
   "metadata": {},
   "source": [
    "---\n",
    "## 10. Clustering Methods Comparison\n",
    "\n",
    "Compare all clustering methods side-by-side.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56087c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive comparison of all clustering methods\n",
    "print(\"=\"*100)\n",
    "print(\"COMPREHENSIVE CLUSTERING METHODS COMPARISON\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "comparison_data = {\n",
    "    'Method': [\n",
    "        'K-Means (Raw)',\n",
    "        'K-Means (Z-Scored)',\n",
    "        'Hierarchical (Raw)',\n",
    "        'Hierarchical (Z-Scored)',\n",
    "        'DBSCAN (Raw)',\n",
    "        'DBSCAN (Z-Scored)'\n",
    "    ],\n",
    "    'Train_Silhouette': [\n",
    "        train_silhouette,\n",
    "        train_silhouette_z,\n",
    "        train_silhouette_hier,\n",
    "        train_silhouette_hier_z,\n",
    "        train_silhouette_dbscan if 'train_silhouette_dbscan' in locals() else -1,\n",
    "        train_silhouette_dbscan_z if 'train_silhouette_dbscan_z' in locals() else -1\n",
    "    ],\n",
    "    'Train_DaviesBouldin': [\n",
    "        train_davies_bouldin,\n",
    "        train_davies_bouldin_z,\n",
    "        train_davies_bouldin_hier,\n",
    "        train_davies_bouldin_hier_z,\n",
    "        train_davies_bouldin_dbscan if 'train_davies_bouldin_dbscan' in locals() else -1,\n",
    "        train_davies_bouldin_dbscan_z if 'train_davies_bouldin_dbscan_z' in locals() else -1\n",
    "    ],\n",
    "    'Validate_Silhouette': [\n",
    "        validate_silhouette,\n",
    "        validate_silhouette_z,\n",
    "        validate_silhouette_hier,\n",
    "        validate_silhouette_hier_z,\n",
    "        validate_silhouette_dbscan if 'validate_silhouette_dbscan' in locals() else -1,\n",
    "        validate_silhouette_dbscan_z if 'validate_silhouette_dbscan_z' in locals() else -1\n",
    "    ],\n",
    "    'Validate_DaviesBouldin': [\n",
    "        validate_davies_bouldin,\n",
    "        validate_davies_bouldin_z,\n",
    "        validate_davies_bouldin_hier,\n",
    "        validate_davies_bouldin_hier_z,\n",
    "        validate_davies_bouldin_dbscan if 'validate_davies_bouldin_dbscan' in locals() else -1,\n",
    "        validate_davies_bouldin_dbscan_z if 'validate_davies_bouldin_dbscan_z' in locals() else -1\n",
    "    ],\n",
    "    'Test_Silhouette': [\n",
    "        test_silhouette,\n",
    "        test_silhouette_z,\n",
    "        test_silhouette_hier,\n",
    "        test_silhouette_hier_z,\n",
    "        test_silhouette_dbscan if 'test_silhouette_dbscan' in locals() else -1,\n",
    "        test_silhouette_dbscan_z if 'test_silhouette_dbscan_z' in locals() else -1\n",
    "    ],\n",
    "    'Test_DaviesBouldin': [\n",
    "        test_davies_bouldin,\n",
    "        test_davies_bouldin_z,\n",
    "        test_davies_bouldin_hier,\n",
    "        test_davies_bouldin_hier_z,\n",
    "        test_davies_bouldin_dbscan if 'test_davies_bouldin_dbscan' in locals() else -1,\n",
    "        test_davies_bouldin_dbscan_z if 'test_davies_bouldin_dbscan_z' in locals() else -1\n",
    "    ]\n",
    "}\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "print(\"\\n\" + comparison_df.to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"INTERPRETATION:\")\n",
    "print(\"  - Silhouette Score: Higher is better (range -1 to 1)\")\n",
    "print(\"  - Davies-Bouldin Index: Lower is better (range 0 to âˆž)\")\n",
    "print(\"  - N/A or negative values indicate insufficient data for metric calculation\")\n",
    "print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b14a7bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82352832",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
