{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e01ec46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yattmeo/Desktop/SMU/Code/404_found_us/.venv/lib/python3.14/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import datasets\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import warnings\n",
    "import json\n",
    "import os\n",
    "import io\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5d124ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column: transaction_id, Data Type: string\n",
      "Column: date, Data Type: timestamp[ns]\n",
      "Column: card_id, Data Type: string\n",
      "Column: amount, Data Type: float32\n",
      "Column: use_chip, Data Type: string\n",
      "Column: merchant_id, Data Type: int64\n",
      "Column: merchant_city, Data Type: string\n",
      "Column: merchant_state, Data Type: string\n",
      "Column: zip, Data Type: float64\n",
      "Column: mcc, Data Type: string\n",
      "Column: errors, Data Type: string\n",
      "Column: is_fraud, Data Type: int64\n",
      "Column: card_brand, Data Type: string\n",
      "Column: card_type, Data Type: string\n",
      "Column: card_number, Data Type: int64\n",
      "Column: expires, Data Type: string\n",
      "Column: cvv, Data Type: int16\n",
      "Column: has_chip, Data Type: string\n",
      "Column: num_cards_issued, Data Type: int64\n",
      "Column: credit_limit, Data Type: float32\n",
      "Column: acct_open_date, Data Type: string\n",
      "Column: year_pin_last_changed, Data Type: int64\n",
      "Column: card_on_dark_web, Data Type: string\n",
      "Column: current_age, Data Type: int64\n",
      "Column: retirement_age, Data Type: int64\n",
      "Column: birth_year, Data Type: int64\n",
      "Column: birth_month, Data Type: int64\n",
      "Column: gender, Data Type: string\n",
      "Column: address, Data Type: string\n",
      "Column: latitude, Data Type: float64\n",
      "Column: longitude, Data Type: float64\n",
      "Column: per_capita_income, Data Type: float32\n",
      "Column: yearly_income, Data Type: float32\n",
      "Column: total_debt, Data Type: float32\n",
      "Column: credit_score, Data Type: int64\n",
      "Column: num_credit_cards, Data Type: int64\n",
      "Column: mcc_description, Data Type: string\n"
     ]
    }
   ],
   "source": [
    "dataset_name = \"thiru1711/Financial_Transactions\"\n",
    "ds = load_dataset(dataset_name)\n",
    "\n",
    "# print(ds)\n",
    "for feature_name, feature_type in ds['train'].features.items():\n",
    "    print(f\"Column: {feature_name}, Data Type: {feature_type.dtype if hasattr(feature_type, 'dtype') else str(feature_type)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ecc5b704",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = ds['train'].to_pandas()\n",
    "\n",
    "# Drop columns not needed\n",
    "drop_cols = [\n",
    "    # PII/Security Fields\n",
    "    'card_number', 'cvv', 'expires', 'address',\n",
    "\n",
    "    # Cardholder Demographics\n",
    "    'current_age', 'retirement_age', 'birth_year', 'birth_month', 'gender',\n",
    "    'latitude', 'longitude', 'per_capita_income', 'yearly_income',\n",
    "    'total_debt', 'credit_score', 'num_credit_cards','credit_limit',\n",
    "\n",
    "    # Account Metadata\n",
    "    'card_id', 'acct_open_date', 'year_pin_last_changed',\n",
    "    'card_on_dark_web', 'num_cards_issued',\n",
    "\n",
    "    # Geographical features\n",
    "    'merchant_state', 'zip', 'merchant_city', 'has_chip'\n",
    "]\n",
    "\n",
    "df = df.drop(columns=drop_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e01b5e4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining columns\n",
      "Column: transaction_id, Data Type: str\n",
      "Column: date, Data Type: datetime64[ns]\n",
      "Column: amount, Data Type: float32\n",
      "Column: use_chip, Data Type: str\n",
      "Column: merchant_id, Data Type: int64\n",
      "Column: mcc, Data Type: int64\n",
      "Column: errors, Data Type: str\n",
      "Column: card_brand, Data Type: str\n",
      "Column: card_type, Data Type: str\n",
      "Column: mcc_description, Data Type: str\n"
     ]
    }
   ],
   "source": [
    "# Convert 'mcc' column to numeric, coercing errors to NaN\n",
    "df['mcc'] = pd.to_numeric(df['mcc'], errors='coerce')\n",
    "\n",
    "# Filter out rows where 'mcc' is NaN after conversion (if any)\n",
    "df = df.dropna(subset=['mcc'])\n",
    "\n",
    "# Filter out rows where is fraud == 1 and then drop the whole column\n",
    "df = df[df['is_fraud'] != 1]\n",
    "\n",
    "# Drop row\n",
    "df = df.drop(columns='is_fraud')\n",
    "\n",
    "# Rename \"Debit (Prepaid)\" to \"Prepaid\" in card_type column\n",
    "df['card_type'] = df['card_type'].replace('Debit (Prepaid)', 'Prepaid')\n",
    "\n",
    "print(f\"Remaining columns\")\n",
    "for feature_name, feature_type in df.dtypes.items():\n",
    "    print(f\"Column: {feature_name}, Data Type: {feature_type}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41987a3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total transactions for MCC 5411: 1592159\n",
      "Year distribution:\n",
      "year\n",
      "2010    147876\n",
      "2011    154463\n",
      "2012    158898\n",
      "2013    162232\n",
      "2014    163821\n",
      "2015    165844\n",
      "2016    166013\n",
      "2017    167323\n",
      "2018    166883\n",
      "2019    138806\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Filter for MCC 5411 (Grocery Stores)\n",
    "df_5411 = df[df['mcc'] == 5411].copy()\n",
    "\n",
    "# Convert transaction_date to datetime and extract year\n",
    "df_5411['date'] = pd.to_datetime(df_5411['date'])\n",
    "df_5411['year'] = df_5411['date'].dt.year\n",
    "\n",
    "print(f\"Total transactions for MCC 5411: {len(df_5411)}\")\n",
    "print(f\"Year distribution:\\n{df_5411['year'].value_counts().sort_index()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ce6c857",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total merchants in MCC 5411: 8158\n",
      "Merchants appearing ONLY in 2017: 327\n",
      "Merchants appearing ONLY in 2018: 362\n",
      "Merchants appearing ONLY in 2019: 300\n"
     ]
    }
   ],
   "source": [
    "# Find merchants that appear in each year\n",
    "merchant_years = df_5411.groupby('merchant_id')['year'].apply(set).reset_index()\n",
    "merchant_years.columns = ['merchant_id', 'years_set']\n",
    "\n",
    "# Find merchants that appear ONLY in 2017 (not in any other year)\n",
    "merchants_only_2017 = merchant_years[merchant_years['years_set'] == {2017}]\n",
    "train_merchant_ids = merchants_only_2017['merchant_id'].tolist()\n",
    "\n",
    "# Find merchants that appear ONLY in 2018 (not in any other year)\n",
    "merchants_only_2018 = merchant_years[merchant_years['years_set'] == {2018}]\n",
    "validate_merchant_ids = merchants_only_2018['merchant_id'].tolist()\n",
    "\n",
    "# Find merchants that appear ONLY in 2019 (not in any other year)\n",
    "merchants_only_2019 = merchant_years[merchant_years['years_set'] == {2019}]\n",
    "test_merchant_ids = merchants_only_2019['merchant_id'].tolist()\n",
    "\n",
    "print(f\"Total merchants in MCC 5411: {len(merchant_years)}\")\n",
    "print(f\"Merchants appearing ONLY in 2017: {len(train_merchant_ids)}\")\n",
    "print(f\"Merchants appearing ONLY in 2018: {len(validate_merchant_ids)}\")\n",
    "print(f\"Merchants appearing ONLY in 2019: {len(test_merchant_ids)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3545403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set (2017 only merchants): 708 transactions, 327 unique merchants\n",
      "Validate set (2018 only merchants): 801 transactions, 362 unique merchants\n",
      "Test set (2019 only merchants): 653 transactions, 300 unique merchants\n",
      "\n",
      "Total: 2162 transactions\n"
     ]
    }
   ],
   "source": [
    "# Create splits using the separate merchant ID lists\n",
    "# Train: merchants that only appear in 2017\n",
    "df_train = df_5411[df_5411['merchant_id'].isin(train_merchant_ids)].copy()\n",
    "\n",
    "# Validate: merchants that only appear in 2018\n",
    "df_validate = df_5411[df_5411['merchant_id'].isin(validate_merchant_ids)].copy()\n",
    "\n",
    "# Test: merchants that only appear in 2019\n",
    "df_test = df_5411[df_5411['merchant_id'].isin(test_merchant_ids)].copy()\n",
    "\n",
    "print(f\"Train set (2017 only merchants): {len(df_train)} transactions, {df_train['merchant_id'].nunique()} unique merchants\")\n",
    "print(f\"Validate set (2018 only merchants): {len(df_validate)} transactions, {df_validate['merchant_id'].nunique()} unique merchants\")\n",
    "print(f\"Test set (2019 only merchants): {len(df_test)} transactions, {df_test['merchant_id'].nunique()} unique merchants\")\n",
    "print(f\"\\nTotal: {len(df_train) + len(df_validate) + len(df_test)} transactions\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f52e96d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year column removed from all splits\n",
      "Train columns: ['transaction_id', 'date', 'amount', 'use_chip', 'merchant_id', 'mcc', 'errors', 'card_brand', 'card_type', 'mcc_description']\n"
     ]
    }
   ],
   "source": [
    "# Drop the year column (temporary helper column)\n",
    "df_train = df_train.drop(columns=['year'])\n",
    "df_validate = df_validate.drop(columns=['year'])\n",
    "df_test = df_test.drop(columns=['year'])\n",
    "\n",
    "print(\"Year column removed from all splits\")\n",
    "print(f\"Train columns: {df_train.columns.tolist()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "585c7cdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets saved to 5411_splits/ directory\n",
      "- 5411_train.csv: 708 rows\n",
      "- 5411_validate.csv: 801 rows\n",
      "- 5411_test.csv: 653 rows\n"
     ]
    }
   ],
   "source": [
    "# Create output directory if it doesn't exist\n",
    "output_dir = '5411_splits'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Save the splits to CSV\n",
    "df_train.to_csv(f'{output_dir}/5411_train.csv', index=False)\n",
    "df_validate.to_csv(f'{output_dir}/5411_validate.csv', index=False)\n",
    "df_test.to_csv(f'{output_dir}/5411_test.csv', index=False)\n",
    "\n",
    "print(f\"Datasets saved to {output_dir}/ directory\")\n",
    "print(f\"- 5411_train.csv: {len(df_train)} rows\")\n",
    "print(f\"- 5411_validate.csv: {len(df_validate)} rows\")\n",
    "print(f\"- 5411_test.csv: {len(df_test)} rows\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "96e9aaa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train merchants: 327\n",
      "Validate merchants: 362\n",
      "Test merchants: 300\n",
      "\n",
      "Overlap between train and validate: 0\n",
      "Overlap between train and test: 0\n",
      "Overlap between validate and test: 0\n",
      "\n",
      "Sets are completely separate (no overlap): True\n"
     ]
    }
   ],
   "source": [
    "# Verification: Check that the merchants are completely separate (no overlap)\n",
    "train_merchants = set(df_train['merchant_id'].unique())\n",
    "validate_merchants = set(df_validate['merchant_id'].unique())\n",
    "test_merchants = set(df_test['merchant_id'].unique())\n",
    "\n",
    "print(f\"Train merchants: {len(train_merchants)}\")\n",
    "print(f\"Validate merchants: {len(validate_merchants)}\")\n",
    "print(f\"Test merchants: {len(test_merchants)}\")\n",
    "print(f\"\\nOverlap between train and validate: {len(train_merchants & validate_merchants)}\")\n",
    "print(f\"Overlap between train and test: {len(train_merchants & test_merchants)}\")\n",
    "print(f\"Overlap between validate and test: {len(validate_merchants & test_merchants)}\")\n",
    "print(f\"\\nSets are completely separate (no overlap): {len(train_merchants & validate_merchants & test_merchants) == 0}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "40af9d57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train merchants (5411 only): 708 transactions, 327 unique merchants\n",
      "  Year distribution: {2017: 708}\n",
      "\n",
      "Validate merchants (5411 only): 801 transactions, 362 unique merchants\n",
      "  Year distribution: {2018: 801}\n",
      "\n",
      "Test merchants (5411 only): 653 transactions, 300 unique merchants\n",
      "  Year distribution: {2019: 653}\n"
     ]
    }
   ],
   "source": [
    "# Get all MCC 5411 transactions for each merchant set independently\n",
    "# Train: all transactions for merchants that only appear in 2017\n",
    "df_train_all = df_5411[df_5411['merchant_id'].isin(train_merchant_ids)].copy()\n",
    "\n",
    "# Validate: all transactions for merchants that only appear in 2018\n",
    "df_validate_all = df_5411[df_5411['merchant_id'].isin(validate_merchant_ids)].copy()\n",
    "\n",
    "# Test: all transactions for merchants that only appear in 2019\n",
    "df_test_all = df_5411[df_5411['merchant_id'].isin(test_merchant_ids)].copy()\n",
    "\n",
    "print(f\"Train merchants (5411 only): {len(df_train_all)} transactions, {df_train_all['merchant_id'].nunique()} unique merchants\")\n",
    "print(f\"  Year distribution: {df_train_all['year'].value_counts().sort_index().to_dict()}\")\n",
    "\n",
    "print(f\"\\nValidate merchants (5411 only): {len(df_validate_all)} transactions, {df_validate_all['merchant_id'].nunique()} unique merchants\")\n",
    "print(f\"  Year distribution: {df_validate_all['year'].value_counts().sort_index().to_dict()}\")\n",
    "\n",
    "print(f\"\\nTest merchants (5411 only): {len(df_test_all)} transactions, {df_test_all['merchant_id'].nunique()} unique merchants\")\n",
    "print(f\"  Year distribution: {df_test_all['year'].value_counts().sort_index().to_dict()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c0d1ee60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transaction_id</th>\n",
       "      <th>date</th>\n",
       "      <th>amount</th>\n",
       "      <th>use_chip</th>\n",
       "      <th>merchant_id</th>\n",
       "      <th>mcc</th>\n",
       "      <th>errors</th>\n",
       "      <th>card_brand</th>\n",
       "      <th>card_type</th>\n",
       "      <th>mcc_description</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9352406</th>\n",
       "      <td>18882165</td>\n",
       "      <td>2017-01-01 07:24:00</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>Chip Transaction</td>\n",
       "      <td>13456</td>\n",
       "      <td>5411</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Discover</td>\n",
       "      <td>Credit</td>\n",
       "      <td>Grocery Stores, Supermarkets</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9352456</th>\n",
       "      <td>18882220</td>\n",
       "      <td>2017-01-01 07:34:00</td>\n",
       "      <td>0.180000</td>\n",
       "      <td>Chip Transaction</td>\n",
       "      <td>13456</td>\n",
       "      <td>5411</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Discover</td>\n",
       "      <td>Credit</td>\n",
       "      <td>Grocery Stores, Supermarkets</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9364365</th>\n",
       "      <td>18896821</td>\n",
       "      <td>2017-01-04 09:05:00</td>\n",
       "      <td>9.330000</td>\n",
       "      <td>Chip Transaction</td>\n",
       "      <td>53657</td>\n",
       "      <td>5411</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mastercard</td>\n",
       "      <td>Debit</td>\n",
       "      <td>Grocery Stores, Supermarkets</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9371915</th>\n",
       "      <td>18906066</td>\n",
       "      <td>2017-01-06 07:40:00</td>\n",
       "      <td>5.960000</td>\n",
       "      <td>Chip Transaction</td>\n",
       "      <td>83089</td>\n",
       "      <td>5411</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Visa</td>\n",
       "      <td>Debit</td>\n",
       "      <td>Grocery Stores, Supermarkets</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9378085</th>\n",
       "      <td>18913687</td>\n",
       "      <td>2017-01-07 16:08:00</td>\n",
       "      <td>95.900002</td>\n",
       "      <td>Chip Transaction</td>\n",
       "      <td>7547</td>\n",
       "      <td>5411</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mastercard</td>\n",
       "      <td>Debit</td>\n",
       "      <td>Grocery Stores, Supermarkets</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        transaction_id                date     amount          use_chip  \\\n",
       "9352406       18882165 2017-01-01 07:24:00   0.240000  Chip Transaction   \n",
       "9352456       18882220 2017-01-01 07:34:00   0.180000  Chip Transaction   \n",
       "9364365       18896821 2017-01-04 09:05:00   9.330000  Chip Transaction   \n",
       "9371915       18906066 2017-01-06 07:40:00   5.960000  Chip Transaction   \n",
       "9378085       18913687 2017-01-07 16:08:00  95.900002  Chip Transaction   \n",
       "\n",
       "         merchant_id   mcc errors  card_brand card_type  \\\n",
       "9352406        13456  5411    NaN    Discover    Credit   \n",
       "9352456        13456  5411    NaN    Discover    Credit   \n",
       "9364365        53657  5411    NaN  Mastercard     Debit   \n",
       "9371915        83089  5411    NaN        Visa     Debit   \n",
       "9378085         7547  5411    NaN  Mastercard     Debit   \n",
       "\n",
       "                      mcc_description  year  \n",
       "9352406  Grocery Stores, Supermarkets  2017  \n",
       "9352456  Grocery Stores, Supermarkets  2017  \n",
       "9364365  Grocery Stores, Supermarkets  2017  \n",
       "9371915  Grocery Stores, Supermarkets  2017  \n",
       "9378085  Grocery Stores, Supermarkets  2017  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "74ddaf3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temporal Split (by year):\n",
      "Train (2017): 167323 transactions, 2848 unique merchants\n",
      "Validate (2018): 166883 transactions, 2828 unique merchants\n",
      "Test (2019): 138806 transactions, 2626 unique merchants\n",
      "\n",
      "Total: 473012 transactions\n"
     ]
    }
   ],
   "source": [
    "# Simple temporal split: split by year (merchants can appear in multiple years)\n",
    "# Train: All MCC 5411 transactions from 2017\n",
    "df_train_temporal = df_5411[df_5411['year'] == 2017].copy()\n",
    "\n",
    "# Validate: All MCC 5411 transactions from 2018\n",
    "df_validate_temporal = df_5411[df_5411['year'] == 2018].copy()\n",
    "\n",
    "# Test: All MCC 5411 transactions from 2019\n",
    "df_test_temporal = df_5411[df_5411['year'] == 2019].copy()\n",
    "\n",
    "print(\"Temporal Split (by year):\")\n",
    "print(f\"Train (2017): {len(df_train_temporal)} transactions, {df_train_temporal['merchant_id'].nunique()} unique merchants\")\n",
    "print(f\"Validate (2018): {len(df_validate_temporal)} transactions, {df_validate_temporal['merchant_id'].nunique()} unique merchants\")\n",
    "print(f\"Test (2019): {len(df_test_temporal)} transactions, {df_test_temporal['merchant_id'].nunique()} unique merchants\")\n",
    "print(f\"\\nTotal: {len(df_train_temporal) + len(df_validate_temporal) + len(df_test_temporal)} transactions\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3f976e36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merchant overlap analysis (temporal split):\n",
      "Merchants in train & validate: 1695\n",
      "Merchants in train & test: 1595\n",
      "Merchants in validate & test: 1619\n",
      "Merchants in all three sets: 1372\n"
     ]
    }
   ],
   "source": [
    "# Check merchant overlap in temporal splits (expected to have overlap)\n",
    "train_merchants_temporal = set(df_train_temporal['merchant_id'].unique())\n",
    "validate_merchants_temporal = set(df_validate_temporal['merchant_id'].unique())\n",
    "test_merchants_temporal = set(df_test_temporal['merchant_id'].unique())\n",
    "\n",
    "print(\"Merchant overlap analysis (temporal split):\")\n",
    "print(f\"Merchants in train & validate: {len(train_merchants_temporal & validate_merchants_temporal)}\")\n",
    "print(f\"Merchants in train & test: {len(train_merchants_temporal & test_merchants_temporal)}\")\n",
    "print(f\"Merchants in validate & test: {len(validate_merchants_temporal & test_merchants_temporal)}\")\n",
    "print(f\"Merchants in all three sets: {len(train_merchants_temporal & validate_merchants_temporal & test_merchants_temporal)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "589220ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temporal datasets saved to 5411_temporal_splits/ directory\n",
      "- 5411_train_temporal.csv: 167323 rows\n",
      "- 5411_validate_temporal.csv: 166883 rows\n",
      "- 5411_test_temporal.csv: 138806 rows\n"
     ]
    }
   ],
   "source": [
    "# Drop the year column before saving\n",
    "df_train_temporal = df_train_temporal.drop(columns=['year'])\n",
    "df_validate_temporal = df_validate_temporal.drop(columns=['year'])\n",
    "df_test_temporal = df_test_temporal.drop(columns=['year'])\n",
    "\n",
    "# Create output directory for temporal splits\n",
    "output_dir_temporal = '5411_temporal_splits'\n",
    "os.makedirs(output_dir_temporal, exist_ok=True)\n",
    "\n",
    "# Save the temporal splits to CSV\n",
    "df_train_temporal.to_csv(f'{output_dir_temporal}/5411_train_temporal.csv', index=False)\n",
    "df_validate_temporal.to_csv(f'{output_dir_temporal}/5411_validate_temporal.csv', index=False)\n",
    "df_test_temporal.to_csv(f'{output_dir_temporal}/5411_test_temporal.csv', index=False)\n",
    "\n",
    "print(f\"Temporal datasets saved to {output_dir_temporal}/ directory\")\n",
    "print(f\"- 5411_train_temporal.csv: {len(df_train_temporal)} rows\")\n",
    "print(f\"- 5411_validate_temporal.csv: {len(df_validate_temporal)} rows\")\n",
    "print(f\"- 5411_test_temporal.csv: {len(df_test_temporal)} rows\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd5be5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir_temporal = '5411_iso_splits'\n",
    "os.makedirs(output_dir_temporal, exist_ok=True)\n",
    "\n",
    "# Save the temporal splits to CSV\n",
    "df_train_all.to_csv(f'{output_dir_temporal}/5411_train_temporal.csv', index=False)\n",
    "df_validate_all.to_csv(f'{output_dir_temporal}/5411_validate_temporal.csv', index=False)\n",
    "df_test_all.to_csv(f'{output_dir_temporal}/5411_test_temporal.csv', index=False)\n",
    "\n",
    "print(f\"isolated year datasets saved to {output_dir_temporal}/ directory\")\n",
    "print(f\"- 5411_train_iso_.csv: {len(df_train_all)} rows\")\n",
    "print(f\"- 5411_validate_iso_.csv: {len(df_validate_all)} rows\")\n",
    "print(f\"- 5411_test_iso_.csv: {len(df_test_all)} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7a733e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
