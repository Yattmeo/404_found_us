{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "74960595",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datasets\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import warnings\n",
    "import json\n",
    "import os\n",
    "import io\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "69eb7ccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration:\n",
      "  Dataset folder: 5411_iso_splits\n",
      "  Cost file: cost_type_id_18feb.csv\n",
      "  Train file: 5411_train_iso.csv\n",
      "  Validate file: 5411_validate_iso.csv\n",
      "  Test file: 5411_test_iso.csv\n"
     ]
    }
   ],
   "source": [
    "# ========== SETTINGS ==========\n",
    "# Configure which dataset to process\n",
    "DATASET_FOLDER = '5411_iso_splits'  # Options: '5411_temporal_splits' or '5411_iso_splits'\n",
    "COST_FILE = 'cost_type_id_18feb.csv'\n",
    "\n",
    "# File naming pattern\n",
    "if 'temporal' in DATASET_FOLDER:\n",
    "    TRAIN_FILE = '5411_train_temporal.csv'\n",
    "    VALIDATE_FILE = '5411_validate_temporal.csv'\n",
    "    TEST_FILE = '5411_test_temporal.csv'\n",
    "    OUTPUT_SUFFIX = '_with_costs'\n",
    "elif 'iso' in DATASET_FOLDER:\n",
    "    TRAIN_FILE = '5411_train_iso.csv'\n",
    "    VALIDATE_FILE = '5411_validate_iso.csv'\n",
    "    TEST_FILE = '5411_test_iso.csv'\n",
    "    OUTPUT_SUFFIX = '_with_costs'\n",
    "else:\n",
    "    # Generic fallback\n",
    "    TRAIN_FILE = '5411_train.csv'\n",
    "    VALIDATE_FILE = '5411_validate.csv'\n",
    "    TEST_FILE = '5411_test.csv'\n",
    "    OUTPUT_SUFFIX = '_with_costs'\n",
    "\n",
    "print(f\"Configuration:\")\n",
    "print(f\"  Dataset folder: {DATASET_FOLDER}\")\n",
    "print(f\"  Cost file: {COST_FILE}\")\n",
    "print(f\"  Train file: {TRAIN_FILE}\")\n",
    "print(f\"  Validate file: {VALIDATE_FILE}\")\n",
    "print(f\"  Test file: {TEST_FILE}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "caf6fbf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set loaded: 708 transactions, 327 unique merchants\n",
      "Validate set loaded: 801 transactions, 362 unique merchants\n",
      "Test set loaded: 653 transactions, 300 unique merchants\n",
      "\n",
      "Total transactions: 2162\n",
      "\n",
      "Train columns: ['transaction_id', 'date', 'amount', 'use_chip', 'merchant_id', 'mcc', 'errors', 'card_brand', 'card_type', 'mcc_description', 'year']\n"
     ]
    }
   ],
   "source": [
    "# Load the splits from the configured folder\n",
    "df_train = pd.read_csv(f'{DATASET_FOLDER}/{TRAIN_FILE}')\n",
    "df_validate = pd.read_csv(f'{DATASET_FOLDER}/{VALIDATE_FILE}')\n",
    "df_test = pd.read_csv(f'{DATASET_FOLDER}/{TEST_FILE}')\n",
    "\n",
    "print(f\"Train set loaded: {len(df_train)} transactions, {df_train['merchant_id'].nunique()} unique merchants\")\n",
    "print(f\"Validate set loaded: {len(df_validate)} transactions, {df_validate['merchant_id'].nunique()} unique merchants\")\n",
    "print(f\"Test set loaded: {len(df_test)} transactions, {df_test['merchant_id'].nunique()} unique merchants\")\n",
    "print(f\"\\nTotal transactions: {len(df_train) + len(df_validate) + len(df_test)}\")\n",
    "print(f\"\\nTrain columns: {df_train.columns.tolist()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "07324eba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost data loaded from cost_type_id_18feb.csv: 62 rows\n",
      "Columns: ['cost_type_ID', 'card_network', 'card_brand', 'fee_program', 'min_transaction_amt', 'max_transaction_amt', 'mcc', 'card_fee_percent', 'card_fee_dollars', 'network_fee_percent', 'network_fee_dollars', 'subtotal_fee_percent', 'subtotal_fee_dollars', 'Unnamed: 13']\n",
      "First few rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cost_type_ID</th>\n",
       "      <th>card_network</th>\n",
       "      <th>card_brand</th>\n",
       "      <th>fee_program</th>\n",
       "      <th>min_transaction_amt</th>\n",
       "      <th>max_transaction_amt</th>\n",
       "      <th>mcc</th>\n",
       "      <th>card_fee_percent</th>\n",
       "      <th>card_fee_dollars</th>\n",
       "      <th>network_fee_percent</th>\n",
       "      <th>network_fee_dollars</th>\n",
       "      <th>subtotal_fee_percent</th>\n",
       "      <th>subtotal_fee_dollars</th>\n",
       "      <th>Unnamed: 13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Visa</td>\n",
       "      <td>Prepaid</td>\n",
       "      <td>Small Ticket Fee Program (All)</td>\n",
       "      <td>0.000</td>\n",
       "      <td>5.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.60%</td>\n",
       "      <td>$0.05</td>\n",
       "      <td>0.13%</td>\n",
       "      <td>$0.02</td>\n",
       "      <td>1.73%</td>\n",
       "      <td>$0.07</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>Visa</td>\n",
       "      <td>Debit</td>\n",
       "      <td>Small Ticket Fee Program (All)</td>\n",
       "      <td>0.000</td>\n",
       "      <td>5.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.05%</td>\n",
       "      <td>$0.21</td>\n",
       "      <td>0.13%</td>\n",
       "      <td>$0.02</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>$0.23</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>Visa</td>\n",
       "      <td>Credit</td>\n",
       "      <td>Small Ticket Fee Program (All)</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.818</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>$0.04</td>\n",
       "      <td>0.14%</td>\n",
       "      <td>$0.02</td>\n",
       "      <td>0.14%</td>\n",
       "      <td>$0.06</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Visa</td>\n",
       "      <td>Credit</td>\n",
       "      <td>Small Ticket Fee Program (All)</td>\n",
       "      <td>1.818</td>\n",
       "      <td>5.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.20%</td>\n",
       "      <td>$0.00</td>\n",
       "      <td>0.14%</td>\n",
       "      <td>$0.02</td>\n",
       "      <td>2.34%</td>\n",
       "      <td>$0.02</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Visa</td>\n",
       "      <td>Super Premium Credit</td>\n",
       "      <td>Small Ticket Fee Program (All)</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.818</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>$0.04</td>\n",
       "      <td>0.14%</td>\n",
       "      <td>$0.02</td>\n",
       "      <td>0.14%</td>\n",
       "      <td>$0.06</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cost_type_ID card_network            card_brand  \\\n",
       "0           1.0         Visa               Prepaid   \n",
       "1           2.0         Visa                 Debit   \n",
       "2           3.0         Visa                Credit   \n",
       "3           4.0         Visa                Credit   \n",
       "4           5.0         Visa  Super Premium Credit   \n",
       "\n",
       "                      fee_program  min_transaction_amt  max_transaction_amt  \\\n",
       "0  Small Ticket Fee Program (All)                0.000                5.000   \n",
       "1  Small Ticket Fee Program (All)                0.000                5.000   \n",
       "2  Small Ticket Fee Program (All)                0.000                1.818   \n",
       "3  Small Ticket Fee Program (All)                1.818                5.000   \n",
       "4  Small Ticket Fee Program (All)                0.000                1.818   \n",
       "\n",
       "   mcc card_fee_percent card_fee_dollars network_fee_percent  \\\n",
       "0  NaN            1.60%            $0.05               0.13%   \n",
       "1  NaN            0.05%            $0.21               0.13%   \n",
       "2  NaN            0.00%            $0.04               0.14%   \n",
       "3  NaN            2.20%            $0.00               0.14%   \n",
       "4  NaN            0.00%            $0.04               0.14%   \n",
       "\n",
       "  network_fee_dollars subtotal_fee_percent subtotal_fee_dollars  Unnamed: 13  \n",
       "0               $0.02                1.73%                $0.07          NaN  \n",
       "1               $0.02                0.18%                $0.23          NaN  \n",
       "2               $0.02                0.14%                $0.06          NaN  \n",
       "3               $0.02                2.34%                $0.02          NaN  \n",
       "4               $0.02                0.14%                $0.06          NaN  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the cost CSV file\n",
    "df_cost = pd.read_csv(COST_FILE)\n",
    "\n",
    "print(f\"Cost data loaded from {COST_FILE}: {len(df_cost)} rows\")\n",
    "print(f\"Columns: {df_cost.columns.tolist()}\")\n",
    "print(f\"First few rows:\")\n",
    "df_cost.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a481c632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TRAIN SET ===\n",
      "Total transactions: 708\n",
      "Rows with cost_type_ID: 661\n",
      "Rows without match: 47\n",
      "\n",
      "=== VALIDATE SET ===\n",
      "Total transactions: 801\n",
      "Rows with cost_type_ID: 743\n",
      "Rows without match: 58\n",
      "\n",
      "=== TEST SET ===\n",
      "Total transactions: 653\n",
      "Rows with cost_type_ID: 604\n",
      "Rows without match: 49\n"
     ]
    }
   ],
   "source": [
    "# Function to apply cost_type_ID to a dataframe\n",
    "def apply_cost_type_id(df, cost_type_df):\n",
    "    \"\"\"Apply cost_type_ID to transaction dataframe based on cost rules\n",
    "    \n",
    "    Note: Column mapping between transaction data and cost data:\n",
    "    - Transaction 'card_brand' (Visa/Mastercard) → Cost 'card_network'\n",
    "    - Transaction 'card_type' (Credit/Debit/Prepaid) → Cost 'card_brand'\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Ensure mcc is same type in both dataframes\n",
    "    df['mcc'] = df['mcc'].astype(float)\n",
    "    cost_type_df['mcc'] = pd.to_numeric(cost_type_df['mcc'], errors='coerce')\n",
    "    \n",
    "    # Filter to only card brands that exist in cost_type_df\n",
    "    df_filtered = df[df['card_brand'].isin(['Visa', 'Mastercard'])].copy()\n",
    "    \n",
    "    # Separate rules\n",
    "    cost_general = cost_type_df[cost_type_df['mcc'].isna()].copy()\n",
    "    cost_specific = cost_type_df[cost_type_df['mcc'].notna()].copy()\n",
    "    \n",
    "    # Process small (<=5): general rules\n",
    "    df_small = df_filtered[df_filtered['amount'] <= 5].merge(\n",
    "        cost_general,\n",
    "        left_on=['card_brand', 'card_type'],\n",
    "        right_on=['card_network', 'card_brand'],\n",
    "        how='left',\n",
    "        suffixes=('', '_cost')\n",
    "    )\n",
    "    df_small = df_small[\n",
    "        (df_small['amount'] >= df_small['min_transaction_amt']) &\n",
    "        (df_small['amount'] <= df_small['max_transaction_amt']) &\n",
    "        (df_small['cost_type_ID'].notna())\n",
    "    ]\n",
    "    df_small = df_small.sort_values('transaction_id').drop_duplicates('transaction_id', keep='first')\n",
    "    \n",
    "    # Process large (>5): mcc-specific rules\n",
    "    df_large = df_filtered[df_filtered['amount'] > 5].merge(\n",
    "        cost_specific,\n",
    "        left_on=['card_brand', 'card_type', 'mcc'],\n",
    "        right_on=['card_network', 'card_brand', 'mcc'],\n",
    "        how='left',\n",
    "        suffixes=('', '_cost')\n",
    "    )\n",
    "    df_large = df_large[\n",
    "        (df_large['amount'] >= df_large['min_transaction_amt']) &\n",
    "        (df_large['amount'] <= df_large['max_transaction_amt']) &\n",
    "        (df_large['cost_type_ID'].notna())\n",
    "    ]\n",
    "    df_large = df_large.sort_values('transaction_id').drop_duplicates('transaction_id', keep='first')\n",
    "    \n",
    "    # Combine results and map back to original df\n",
    "    result_map = pd.concat([\n",
    "        df_small[['transaction_id', 'cost_type_ID']],\n",
    "        df_large[['transaction_id', 'cost_type_ID']]\n",
    "    ]).set_index('transaction_id')['cost_type_ID']\n",
    "    \n",
    "    # Drop old cost_type_ID if exists\n",
    "    if 'cost_type_ID' in df.columns:\n",
    "        df = df.drop('cost_type_ID', axis=1)\n",
    "    \n",
    "    df['cost_type_ID'] = df['transaction_id'].map(result_map)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Apply cost_type_ID to all three datasets\n",
    "df_train = apply_cost_type_id(df_train, df_cost)\n",
    "df_validate = apply_cost_type_id(df_validate, df_cost)\n",
    "df_test = apply_cost_type_id(df_test, df_cost)\n",
    "\n",
    "print(\"=== TRAIN SET ===\")\n",
    "print(f\"Total transactions: {len(df_train)}\")\n",
    "print(f\"Rows with cost_type_ID: {df_train['cost_type_ID'].notna().sum()}\")\n",
    "print(f\"Rows without match: {df_train['cost_type_ID'].isna().sum()}\")\n",
    "\n",
    "print(\"\\n=== VALIDATE SET ===\")\n",
    "print(f\"Total transactions: {len(df_validate)}\")\n",
    "print(f\"Rows with cost_type_ID: {df_validate['cost_type_ID'].notna().sum()}\")\n",
    "print(f\"Rows without match: {df_validate['cost_type_ID'].isna().sum()}\")\n",
    "\n",
    "print(\"\\n=== TEST SET ===\")\n",
    "print(f\"Total transactions: {len(df_test)}\")\n",
    "print(f\"Rows with cost_type_ID: {df_test['cost_type_ID'].notna().sum()}\")\n",
    "print(f\"Rows without match: {df_test['cost_type_ID'].isna().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "471630cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TRAIN SET ===\n",
      "✓ proc_cost calculated for 661 transactions\n",
      "\n",
      "=== VALIDATE SET ===\n",
      "✓ proc_cost calculated for 743 transactions\n",
      "\n",
      "=== TEST SET ===\n",
      "✓ proc_cost calculated for 604 transactions\n"
     ]
    }
   ],
   "source": [
    "# Prepare lookup arrays indexed by cost_type_ID\n",
    "df_cost['subtotal_fee_percent_clean'] = df_cost['subtotal_fee_percent'].str.rstrip('%').astype(float) / 100\n",
    "df_cost['subtotal_fee_dollars_clean'] = df_cost['subtotal_fee_dollars'].str.lstrip('$').astype(float)\n",
    "\n",
    "# Create dictionaries for O(1) lookup\n",
    "fee_dollars_map = dict(zip(df_cost['cost_type_ID'], df_cost['subtotal_fee_dollars_clean']))\n",
    "fee_percent_map = dict(zip(df_cost['cost_type_ID'], df_cost['subtotal_fee_percent_clean']))\n",
    "\n",
    "# Apply proc_cost calculation to all three datasets\n",
    "df_train['proc_cost'] = df_train['cost_type_ID'].map(fee_dollars_map) + (df_train['cost_type_ID'].map(fee_percent_map) * df_train['amount'])\n",
    "df_validate['proc_cost'] = df_validate['cost_type_ID'].map(fee_dollars_map) + (df_validate['cost_type_ID'].map(fee_percent_map) * df_validate['amount'])\n",
    "df_test['proc_cost'] = df_test['cost_type_ID'].map(fee_dollars_map) + (df_test['cost_type_ID'].map(fee_percent_map) * df_test['amount'])\n",
    "\n",
    "print(\"=== TRAIN SET ===\")\n",
    "print(f\"✓ proc_cost calculated for {df_train['proc_cost'].notna().sum():,} transactions\")\n",
    "\n",
    "print(\"\\n=== VALIDATE SET ===\")\n",
    "print(f\"✓ proc_cost calculated for {df_validate['proc_cost'].notna().sum():,} transactions\")\n",
    "\n",
    "print(\"\\n=== TEST SET ===\")\n",
    "print(f\"✓ proc_cost calculated for {df_test['proc_cost'].notna().sum():,} transactions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3568bc07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preview files saved:\n",
      "- preview_train_costed.csv\n",
      "- preview_validate_costed.csv\n",
      "- preview_test_costed.csv\n"
     ]
    }
   ],
   "source": [
    "# Save preview of costed transactions from each dataset\n",
    "df_train.head(25).to_csv('preview_train_costed.csv', index=False)\n",
    "df_validate.head(25).to_csv('preview_validate_costed.csv', index=False)\n",
    "df_test.head(25).to_csv('preview_test_costed.csv', index=False)\n",
    "\n",
    "print(\"Preview files saved:\")\n",
    "print(\"- preview_train_costed.csv\")\n",
    "print(\"- preview_validate_costed.csv\")\n",
    "print(\"- preview_test_costed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9de4155e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets with costs saved to 5411_iso_splits/ directory:\n",
      "- 5411_train_iso_with_costs.csv: 708 rows\n",
      "- 5411_validate_iso_with_costs.csv: 801 rows\n",
      "- 5411_test_iso_with_costs.csv: 653 rows\n",
      "\n",
      "Columns in saved files: ['transaction_id', 'date', 'amount', 'use_chip', 'merchant_id', 'mcc', 'errors', 'card_brand', 'card_type', 'mcc_description', 'year', 'cost_type_ID', 'proc_cost']\n"
     ]
    }
   ],
   "source": [
    "# Save the costed datasets back to the same folder\n",
    "train_output = TRAIN_FILE.replace('.csv', f'{OUTPUT_SUFFIX}.csv')\n",
    "validate_output = VALIDATE_FILE.replace('.csv', f'{OUTPUT_SUFFIX}.csv')\n",
    "test_output = TEST_FILE.replace('.csv', f'{OUTPUT_SUFFIX}.csv')\n",
    "\n",
    "df_train.to_csv(f'{DATASET_FOLDER}/{train_output}', index=False)\n",
    "df_validate.to_csv(f'{DATASET_FOLDER}/{validate_output}', index=False)\n",
    "df_test.to_csv(f'{DATASET_FOLDER}/{test_output}', index=False)\n",
    "\n",
    "print(f\"Datasets with costs saved to {DATASET_FOLDER}/ directory:\")\n",
    "print(f\"- {train_output}: {len(df_train)} rows\")\n",
    "print(f\"- {validate_output}: {len(df_validate)} rows\")\n",
    "print(f\"- {test_output}: {len(df_test)} rows\")\n",
    "print(f\"\\nColumns in saved files: {df_train.columns.tolist()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d942fe0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9192f42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "34a54d20",
   "metadata": {},
   "source": [
    "# Diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2e86b9fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Transaction Data Columns ===\n",
      "['transaction_id', 'date', 'amount', 'use_chip', 'merchant_id', 'mcc', 'errors', 'card_brand', 'card_type', 'mcc_description', 'year', 'cost_type_ID', 'proc_cost']\n",
      "\n",
      "=== Cost Data Columns ===\n",
      "['cost_type_ID', 'card_network', 'card_brand', 'fee_program', 'min_transaction_amt', 'max_transaction_amt', 'mcc', 'card_fee_percent', 'card_fee_dollars', 'network_fee_percent', 'network_fee_dollars', 'subtotal_fee_percent', 'subtotal_fee_dollars', 'Unnamed: 13', 'subtotal_fee_percent_clean', 'subtotal_fee_dollars_clean']\n",
      "\n",
      "=== Transaction Data Sample ===\n",
      "   transaction_id                 date  amount          use_chip  merchant_id  \\\n",
      "0        18882165  2017-01-01 07:24:00    0.24  Chip Transaction        13456   \n",
      "1        18882220  2017-01-01 07:34:00    0.18  Chip Transaction        13456   \n",
      "2        18896821  2017-01-04 09:05:00    9.33  Chip Transaction        53657   \n",
      "\n",
      "      mcc errors  card_brand card_type               mcc_description  year  \\\n",
      "0  5411.0    NaN    Discover    Credit  Grocery Stores, Supermarkets  2017   \n",
      "1  5411.0    NaN    Discover    Credit  Grocery Stores, Supermarkets  2017   \n",
      "2  5411.0    NaN  Mastercard     Debit  Grocery Stores, Supermarkets  2017   \n",
      "\n",
      "   cost_type_ID  proc_cost  \n",
      "0           NaN        NaN  \n",
      "1           NaN        NaN  \n",
      "2          38.0   0.290094  \n",
      "\n",
      "=== Cost Data Sample ===\n",
      "   cost_type_ID card_network card_brand                     fee_program  \\\n",
      "0           1.0         Visa    Prepaid  Small Ticket Fee Program (All)   \n",
      "1           2.0         Visa      Debit  Small Ticket Fee Program (All)   \n",
      "2           3.0         Visa     Credit  Small Ticket Fee Program (All)   \n",
      "\n",
      "   min_transaction_amt  max_transaction_amt  mcc card_fee_percent  \\\n",
      "0                  0.0                5.000  NaN            1.60%   \n",
      "1                  0.0                5.000  NaN            0.05%   \n",
      "2                  0.0                1.818  NaN            0.00%   \n",
      "\n",
      "  card_fee_dollars network_fee_percent network_fee_dollars  \\\n",
      "0            $0.05               0.13%               $0.02   \n",
      "1            $0.21               0.13%               $0.02   \n",
      "2            $0.04               0.14%               $0.02   \n",
      "\n",
      "  subtotal_fee_percent subtotal_fee_dollars  Unnamed: 13  \\\n",
      "0                1.73%                $0.07          NaN   \n",
      "1                0.18%                $0.23          NaN   \n",
      "2                0.14%                $0.06          NaN   \n",
      "\n",
      "   subtotal_fee_percent_clean  subtotal_fee_dollars_clean  \n",
      "0                      0.0173                        0.07  \n",
      "1                      0.0018                        0.23  \n",
      "2                      0.0014                        0.06  \n"
     ]
    }
   ],
   "source": [
    "# Check columns in both dataframes\n",
    "print(\"=== Transaction Data Columns ===\")\n",
    "print(df_train.columns.tolist())\n",
    "print(\"\\n=== Cost Data Columns ===\")\n",
    "print(df_cost.columns.tolist())\n",
    "print(\"\\n=== Transaction Data Sample ===\")\n",
    "print(df_train.head(3))\n",
    "print(\"\\n=== Cost Data Sample ===\")\n",
    "print(df_cost.head(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7812776c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ANALYSIS OF UNMATCHED TRANSACTIONS (TRAIN SET) ===\n",
      "\n",
      "Total unmatched: 47\n",
      "\n",
      "1. Card Brand Distribution (unmatched):\n",
      "card_brand\n",
      "Amex        35\n",
      "Discover    12\n",
      "Name: count, dtype: int64\n",
      "\n",
      "2. Card Type Distribution (unmatched):\n",
      "card_type\n",
      "Credit    47\n",
      "Name: count, dtype: int64\n",
      "\n",
      "3. Amount Statistics (unmatched):\n",
      "   Min: $0.18\n",
      "   Max: $175.78\n",
      "   Mean: $24.46\n",
      "   Negative amounts: 0\n",
      "\n",
      "4. Sample of unmatched transactions:\n",
      "     transaction_id card_brand card_type  amount     mcc\n",
      "0          18882165   Discover    Credit    0.24  5411.0\n",
      "1          18882220   Discover    Credit    0.18  5411.0\n",
      "9          18921413       Amex    Credit   15.77  5411.0\n",
      "49         19080931       Amex    Credit    2.08  5411.0\n",
      "71         19114177       Amex    Credit   71.03  5411.0\n",
      "91         19147263       Amex    Credit   10.06  5411.0\n",
      "124        19295878       Amex    Credit   23.73  5411.0\n",
      "135        19321294       Amex    Credit    9.47  5411.0\n",
      "140        19340588       Amex    Credit    8.14  5411.0\n",
      "142        19343183       Amex    Credit  175.78  5411.0\n",
      "\n",
      "=== COST DATA COVERAGE ===\n",
      "\n",
      "Card networks in cost data:\n",
      "<ArrowStringArray>\n",
      "['Visa', 'Mastercard', nan]\n",
      "Length: 3, dtype: str\n",
      "\n",
      "Card brands in cost data:\n",
      "<ArrowStringArray>\n",
      "['Prepaid', 'Debit', 'Credit', 'Super Premium Credit', nan]\n",
      "Length: 5, dtype: str\n"
     ]
    }
   ],
   "source": [
    "# Analyze unmatched transactions in train set\n",
    "unmatched_train = df_train[df_train['cost_type_ID'].isna()].copy()\n",
    "\n",
    "print(\"=== ANALYSIS OF UNMATCHED TRANSACTIONS (TRAIN SET) ===\\n\")\n",
    "print(f\"Total unmatched: {len(unmatched_train)}\")\n",
    "\n",
    "print(\"\\n1. Card Brand Distribution (unmatched):\")\n",
    "print(unmatched_train['card_brand'].value_counts())\n",
    "\n",
    "print(\"\\n2. Card Type Distribution (unmatched):\")\n",
    "print(unmatched_train['card_type'].value_counts())\n",
    "\n",
    "print(\"\\n3. Amount Statistics (unmatched):\")\n",
    "print(f\"   Min: ${unmatched_train['amount'].min():.2f}\")\n",
    "print(f\"   Max: ${unmatched_train['amount'].max():.2f}\")\n",
    "print(f\"   Mean: ${unmatched_train['amount'].mean():.2f}\")\n",
    "print(f\"   Negative amounts: {(unmatched_train['amount'] < 0).sum()}\")\n",
    "\n",
    "print(\"\\n4. Sample of unmatched transactions:\")\n",
    "print(unmatched_train[['transaction_id', 'card_brand', 'card_type', 'amount', 'mcc']].head(10))\n",
    "\n",
    "# Check what card brands and types are in the cost data\n",
    "print(\"\\n=== COST DATA COVERAGE ===\")\n",
    "print(\"\\nCard networks in cost data:\")\n",
    "print(df_cost['card_network'].unique())\n",
    "print(\"\\nCard brands in cost data:\")\n",
    "print(df_cost['card_brand'].unique())\n",
    "\n",
    "# For Visa/Mastercard transactions that are still unmatched\n",
    "visa_mc_unmatched = unmatched_train[unmatched_train['card_brand'].isin(['Visa', 'Mastercard'])]\n",
    "if len(visa_mc_unmatched) > 0:\n",
    "    print(f\"\\n5. Visa/Mastercard transactions that didn't match: {len(visa_mc_unmatched)}\")\n",
    "    print(\"   Card type distribution:\")\n",
    "    print(visa_mc_unmatched['card_type'].value_counts())\n",
    "    print(\"\\n   Sample:\")\n",
    "    print(visa_mc_unmatched[['transaction_id', 'card_brand', 'card_type', 'amount', 'mcc']].head(10))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
